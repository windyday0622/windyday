{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/windyday0622/windyday/blob/main/m6_%EB%94%A5%EB%9F%AC%EB%8B%9D/%20m6_%EB%94%A5%EB%9F%AC%EB%8B%9D_%EB%AA%A8%EB%8D%B8%EA%B5%AC%EC%B6%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBb8o_BCCCm2"
      },
      "source": [
        "## TensorFlow, Keras\n",
        "딥러닝 모델을 개발, 훈련, 평가, 배포하는 데 필요한 도구와 라이브러리를 제공하며 딥러닝을 효율적이고 쉽게 구현할 수 있도록 다양한 기능을 갖추고 있는 딥러닝 프레임워크이다.\n",
        "\n",
        "- TensorFlow: 딥러닝 모델을 정의하고 구축할 수 있는 다양한 API를 제공합니다. 고수준 API(tf.keras)와 저수준 API를 통해 다양한 모델을 유연하게 설계할 수 있습니다.\n",
        "- Keras: TensorFlow 위에서 작동하는 고수준 API로, 사용자가 간단하고 직관적으로 모델을 정의할 수 있게 도와줍니다. 직관적인 레이어 기반의 접근 방식을 사용해 빠르게 모델을 구축할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSkOhzFjCCPW"
      },
      "source": [
        "텐서플로우(TensorFlow)의 케라스(Keras)\n",
        "\n",
        "- 머신러닝 모델을 쉽고 빠르게 개발할 수 있도록 도와주는 고수준의 신경망 API. 원래 케라스는 독립적인 딥러닝 라이브러리로 시작되었지만, 텐서플로우 1.0 버전부터는 텐서플로우의 공식 프론트엔드로 통합되었고, 텐서플로우 2.0 이후부터는 텐서플로우의 기본 API로 자리잡았다.\n",
        "- 케라스는 사용자 친화적이며 모듈식으로 구성되어 있어, 신경망의 레이어(layer), 활성화 함수(activation function), 손실 함수(loss function) 등을 마치 레고 블록을 조립하듯 쉽게 조합하여 모델을 구성할 수 있다. 이를 통해 컴퓨터 비전, 자연어 처리와 같은 다양한 머신러닝 애플리케이션을 신속하게 개발할 수 있다.\n",
        "\n",
        "주요 특징\n",
        "\n",
        "- 사용자 친화성: 케라스는 일관된 API를 제공하며, 일반적인 사용 사례에 대한 간결한 코드를 지향합니다. 이를 통해 사용자가 직관적으로 이해하고 사용할 수 있다.\n",
        "- 모듈성: 모델은 독립적인 모듈, 즉 레이어, 손실 함수, 활성화 함수, 최적화 알고리즘 등의 조합으로 구성됩니다. 이러한 모듈은 최소한의 제약으로 서로 연결될 수 있어, 매우 유연한 모델 설계가 가능.\n",
        "- 확장성: 케라스는 새로운 레이어나 기타 모듈을 만들어 추가하는 것이 상대적으로 쉽습니다. 따라서 연구 목적으로 새로운 아이디어를 실험하고자 할 때 매우 유용.\n",
        "- 파이썬 기반: 케라스는 순수 파이썬으로 작성되어 있으며, 딥러닝 모델을 파이썬 코드로 쉽게 작성할 수 있다.\n",
        "\n",
        "기본 구성 요소\n",
        "- 모델: Sequential 모델과 함수형 API를 통해 신경망을 구성할 수 있다. - Sequential 모델은 레이어를 순차적으로 쌓는 간단한 방식이며, 함수형 API는 더 복잡한 모델을 구성할 수 있는 유연성을 제공.\n",
        "- 레이어: 다양한 유형의 레이어(예: Dense(완전 연결 레이어), Conv2D(2D 컨볼루션 레이어), RNN(재귀 신경망 레이어))를 제공.\n",
        "- 손실 함수: 모델의 예측과 실제 값 사이의 차이를 측정하는 함수입니다. 예를 들어, 회귀 문제에는 mean_squared_error, 분류 문제에는 categorical_crossentropy가 자주 사용.\n",
        "- 옵티마이저: 경사하강법 알고리즘을 구현한 것으로, adam, sgd, rmsprop 등이 있다. 모델의 손실을 최소화하기 위해 모델 파라미터를 업데이트하는 방법을 정의.\n",
        "- 평가 지표: 학습과 테스트 단계에서 모델의 성능을 평가하기 위해 사용되는 지표들이다. 예를 들어, 정확도(accuracy), 정밀도(precision), 재현율(recall) 등이 있다.\n",
        "\n",
        "케라스는 이러한 구성 요소들을 사용하여 다양한 신경망 아키텍처를 구현하고, 이를 텐서플로우 백엔드를 통해 효율적으로 실행할 수 있게 해준다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXQeACjnCakv"
      },
      "source": [
        "### 텐서플로우(TensorFlow) 모델 구축 방법\n",
        "Sequential API와 함수형(Functional) API. 이 두 방법은 신경망 모델을 정의, 구축 및 실험하는 데 사용되며, 사용자의 필요와 모델의 복잡성에 따라 적합한 방법을 선택할 수 있다.\n",
        "\n",
        "Sequential API\n",
        "- Sequential API는 가장 간단한 형태의 모델을 생성하는 방법 중 하나로, 레이어를 순차적으로 쌓아 올리는 방식으로 모델을 정의. 각 레이어는 바로 이전 레이어의 출력을 입력으로 받아 처리.\n",
        "- Sequential 모델은 단순한 순차적 구조를 가진 신경망에 적합하며, 복잡한 모델 구조(예: 다중 입력/출력, 모델 내 레이어 간 병렬 연결 등)를 표현하는 데는 한계가 있다.\n",
        "\n",
        "함수형(Functional) API\n",
        "- 함수형 API는 더 유연한 모델 설계를 가능하게 하는 API로, 복잡한 모델 아키텍처를 구성할 수 있다.\n",
        "- 함수형 API를 사용하면 다중 입력 및 출력, 공유 레이어(동일한 레이어를 여러 번 사용), 레이어 간 복잡한 연결 구조 등을 정의할 수 있다. 이는 각 레이어의 입출력을 명시적으로 정의함으로써 달성된다. 함수형 API는 고급 사용자에게 더 많은 유연성과 제어력을 제공한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWKUcgA4LYQt"
      },
      "source": [
        "[ 활성화 함수 ]\n",
        "- ReLU(Rectified Linear Unit): 'f(x) = max(0, x)'로 정의되어 널리 사용되는 활성화 함수입니다. 계산 효율성이 높으면서도 비선형성이 도입되어 훈련 중에 모델이 빠르게 수렴될 수 있다.\n",
        "- 시그모이드: 이 활성화 함수는 0과 1 사이의 값을 출력하므로 이진 분류 문제에 적합.\n",
        "- 소프트맥스: 각 클래스에 대한 확률을 얻기 위해 분류기의 출력 레이어에서 자주 사용되는 소프트맥스 함수는 여러 클래스에 대한 확률 분포를 출력.\n",
        "- Tanh(하이퍼볼릭 탄젠트): 시그모이드와 비슷하지만 -1과 1 사이의 값을 출력."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSzU-kMvB-h1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(28*28,)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zERUYTaSPchK"
      },
      "source": [
        "- 신경망 및 딥러닝의 맥락에서 옵티마이저는 손실을 줄이기 위해 가중치, 학습률 등 신경망의 속성을 변경하는 데 사용되는 알고리즘 또는 방법.\n",
        "- 옵티마이저는 학습 프로세스의 속도와 품질에 직접적인 영향을 미치므로 학습 프로세스에 매우 중요.\n",
        "- 최적화의 목표는 비용 함수(또는 손실 함수)를 최소화하는 모델에 대한 최상의 매개변수(가중치)를 찾는 것이다. 이 프로세스는 모델이 특정 작업에 대한 정확성과 성능을 향상시키는 데 필수적이다.\n",
        "\n",
        "[ 옵티마이저 유형 ]\n",
        "\n",
        "가중치를 조정하기 위한 자체 메커니즘과 전략을 가진 여러 가지 최적화 프로그램이 있습니다. 가장 일반적으로 사용되는 최적화 도구는 다음과 같다.\n",
        "\n",
        "- 확률적 경사하강법(SGD): 이것은 가장 간단한 최적화 프로그램 중 하나. 각 훈련 예제를 개별적으로 사용하여 모델의 가중치를 업데이트. 여기에는 각 단계에서 훈련 데이터의 하위 집합을 사용하여 더 효율적으로 만드는 미니 배치 경사하강법(Mini-Batch Gradient Descent)과 같은 변형이 있다.\n",
        "- 모멘텀: 이 최적화 프로그램은 관련 방향을 따라 탐색하여 SGD를 가속화하고 현재 업데이트 벡터에 과거 단계의 업데이트 벡터의 일부를 추가하여 높은 곡률 방향의 진동을 완화.\n",
        "- Adagrad: 학습 속도를 매개변수에 맞게 조정하여 자주 발생하는 기능과 관련된 매개변수에 대해 더 작은 업데이트를 수행하고, 자주 발생하지 않는 기능과 관련된 매개변수에 대해 더 큰 업데이트를 수행.\n",
        "\n",
        "[가장 많이 쓰는 거]\n",
        "- RMSprop: 이 최적화 프로그램은 가중치에 대한 학습률을 해당 가중치에 대한 최근 기울기 크기의 이동 평균으로 나눈다. 이는 Geoff Hinton이 강의에서 제안한 미공개 적응형 학습률 방법.\n",
        "- Adam(Adaptive Moment Estimation): AdaGrad 및 RMSprop 알고리즘의 최상의 속성을 결합하여 노이즈 문제에 대한 희소 기울기를 처리할 수 있는 최적화 알고리즘을 제공.\n",
        "\n",
        "[ 옵티마이저 작동 방식 ]\n",
        "\n",
        "- 최적화 프로그램은 모델 매개변수에 대한 손실 함수의 기울기를 사용하여 조정. 이 기울기는 손실을 최소화하기 위해 가중치를 조정해야 하는 방향을 나타낸다. 가중치를 반복적으로 업데이트함으로써 최적화 프로그램은 모델의 최고 성능에 해당하는 손실 함수의 가장 낮은 지점에 도달하려고 한다.\n",
        "- 최적화 프로그램의 선택은 신경망의 성능에 큰 영향을 미칠 수 있으며, 최선의 선택은 특정 문제, 데이터의 성격, 신경망 아키텍처에 따라 달라질 수 있다. Adam은 다양한 문제에 대한 적응성과 성능으로 인해 기본적으로 좋은 선택이 되는 경우가 많지만, 특정 작업과 데이터 세트에는 다른 최적화 프로그램이 도움이 될 수 있다. 주어진 시나리오에 가장 효과적인 최적화 프로그램을 식별하려면 일반적으로 실험과 교차 검증이 필요하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ7SqFsOPdJS"
      },
      "source": [
        "[ 손실 함수라고도 알려진 비용 함수 ]\n",
        "- 모델의 예측 출력과 실제 목표 값 간의 차이를 측정하는 수학적 함수입니다. 이는 모델의 오류를 정량화하여 훈련 중 최적화 프로세스에 대한 가이드 역할을 한다.\n",
        "- 신경망 훈련의 목표는 이 비용 함수를 최소화하는 것이다. 이는 모델이 예측하는 것과 실제로 관찰되는 것 사이의 오류를 효과적으로 줄이는 것을 의미.\n",
        "- 고급 신경망 API인 Keras는 다양한 유형의 문제에 대해 다양한 비용 함수를 내장하고 있으며 필요한 경우 사용자 정의 손실 함수를 생성할 수도 있다. 비용 함수의 선택은 분류, 회귀 등과 같이 해결되는 문제의 구체적인 성격에 따라 달라다.\n",
        "\n",
        "[ Keras의 일반적인 비용 함수 ]\n",
        "- 평균 제곱 오차(MSE): 회귀 문제에 사용됩니다. 예측값과 실제값 사이의 오차 제곱의 평균을 계산. keras.losses.MeanSquaredError()\n",
        "- 이진 교차엔트로피: 이진 분류 문제에 사용됩니다. 두 확률 분포, 즉 실제 레이블 분포와 예측 확률 사이의 거리를 측정. keras.losses.BinaryCrossentropy()\n",
        "- 범주형 교차엔트로피: 레이블이 원-핫 인코딩되는 다중 클래스 분류 문제에 사용. 이진 교차엔트로피와 유사하지만 여러 클래스에 적용. keras.losses.keras.losses.CategoricalCrossentropy()\n",
        "- 희소 범주형 교차엔트로피: 범주형 교차엔트로피와 유사하지만 레이블이 정수인 경우에 사용됩니다. 클래스가 많은 경우에는 메모리 효율성이 더 높다. keras.losses.SparseCategoricalCrossentropy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KR457sJSaNj"
      },
      "source": [
        "Q. 모델 컴파일하기 - 옵티마이저, 손실함수, 평가 지표 설정하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWmI8bWJCdAd"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQYv9RilSx4D"
      },
      "source": [
        "[ 배치 크기 ]\n",
        "- 배치 크기는 기계 학습에 사용되는 용어로, 모델 학습 프로세스의 한 번의 반복에서 활용되는 학습 예제의 수를 나타낸다.\n",
        "- 신경망 훈련의 맥락에서 데이터 세트는 일반적으로 여러 배치로 나뉘며 모델의 가중치는 각 배치를 처리한 후 업데이트된다.\n",
        "- 배치 크기의 선택은 수렴 속도와 훈련 프로세스의 안정성을 포함한 훈련 역학에 큰 영향을 미칠 수 있다.\n",
        "\n",
        "- 작은 배치 크기: 각 업데이트 내에서 더 많은 노이즈로 더 빠른 업데이트가 가능. 이는 때때로 모델이 로컬 최소값을 벗어나는 데 도움이 될 수 있지만 훈련 과정을 더욱 불안정하게 만들 수도 있다.\n",
        "- 대형 배치 크기: 기울기에 대한 더 정확한 추정치를 제공하며 업데이트 시 노이즈가 적다. 이는 더 안정적이지만 잠재적으로 더 느린 훈련으로 이어질 수 있습니다. 또한 대규모 배치에는 더 많은 메모리가 필요하므로 일부 하드웨어에서는 제한 요소가 될 수 있다.\n",
        "\n",
        "[ 에포크 ]\n",
        "- 에포크는 전체 훈련 데이터세트를 한 번 통과하는 것을 나타낸다. 한 epoch 동안 신경망은 모든 훈련 예제를 한 번 처리한다. 따라서 훈련의 에포크 수에 따라 학습 알고리즘이 전체 훈련 데이터 세트에서 작동하는 횟수가 결정된다.\n",
        "- 너무 적은 에포크를 실행하면 모델이 훈련 데이터에서 충분히 학습하지 못하는 과소적합이 발생할 수 있다.\n",
        "- 너무 많은 에포크를 실행하면 과적합이 발생할 수 있다. 즉, 모델이 노이즈를 포함하여 훈련 데이터에서 패턴을 너무 잘 학습하여 보이지 않는 데이터에 대한 성능이 저하될 수 있다.\n",
        "\n",
        "[ 배치 크기와 에포크 간의 관계 ]\n",
        "- 배치 크기 영향: 배치 크기는 가중치를 업데이트하기 전에 확인하는 예시 수를 결정. 배치가 작을수록 한번에 더 많은 업데이트가 이루어지며 잠재적으로 학습 속도가 빨라지지만 너무 작으면 불안정해질 수 있다. 배치가 클수록 더 안정적인 기울기 추정이 제공되지만 학습 속도가 느려지고 더 많은 메모리가 필요할 수 있다.\n",
        "- 에포크 영향: 에포크 수에 따라 학습 알고리즘이 전체 데이터 세트를 순환하는 횟수가 결정. Epoch가 많을수록 모델이 가중치를 학습하고 조정할 수 있는 기회가 더 많아지지만 숫자가 너무 높으면 과적합이 발생할 위험이 있다.\n",
        "- 요약하자면, 배치 크기와 에포크 수는 신중하게 균형을 맞춰야 하는 신경망 훈련의 두 가지 기본 하이퍼파라미터이다. 이러한 매개변수의 최적 설정은 특정 데이터세트와 문제는 물론 사용 가능한 계산 리소스에 따라 달라진다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiFmXHDbU4EC"
      },
      "source": [
        "Q. 모델을 간단한 데이터셋에 적용하여 학습하기\n",
        "- MNIST 데이터셋을 사용\n",
        "- 배치 사이즈는 32, 에포크 수는 10으로 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FSNMdalCc-d",
        "outputId": "a2bbc0e8-c353-4ad4-90e0-8ab00da17070"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8335 - loss: 0.5538\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9505 - loss: 0.1701\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9630 - loss: 0.1260\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9697 - loss: 0.0991\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9731 - loss: 0.0838\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9773 - loss: 0.0741\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9801 - loss: 0.0621\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0581\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0486\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0479\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b0d678de440>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 784)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 784)).astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4b39BarWNrC"
      },
      "source": [
        "Q. 모델 평가하기\n",
        "- 테스트 데이터셋을 사용하여 모델을 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lq6WCdHCc6e",
        "outputId": "28a9bd86-04a8-4db1-8191-78df62e789a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9696 - loss: 0.1067\n",
            "Test accuracy: 0.9718000292778015\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "iuSS4M5jCc4W",
        "outputId": "91ca4296-a178-47af-d03a-2a2d5923d45b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,120</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m25,120\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,648</span> (326.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m83,648\u001b[0m (326.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,882</span> (108.91 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,882\u001b[0m (108.91 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,766</span> (217.84 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m55,766\u001b[0m (217.84 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoM_SwQrX9oK"
      },
      "source": [
        "Q. MNIST 데이터셋에 대하여 Sequential 모델을 사용하여 간단한 완전 연결 신경망(Feedforward Neural Network) 구성하세요.\n",
        "- 입력 형태(input_shape): input_shape=(28, 28)로 설정. 이는 모델이 28x28 픽셀 크기의 이미지를 입력으로 받는다는 것을 의미이며 첫 번째 레이어인 Flatten은 이 2D 이미지를 784(28x28) 요소의 1D 배열로 평탄화.Flatten(input_shape=(28, 28))\n",
        "\n",
        "- 레이어 구성: 모델은 평탄화 레이어(Flatten) 다음에 128개의 뉴런을 가진 완전 연결 레이어(Dense)를 가지고 있으며, 그 다음에는 10개의 출력 뉴런을 가진 또 다른 Dense 레이어가 있다. 출력 레이어는 소프트맥스 활성화 함수를 사용하여 다중 클래스 분류를 수행.\n",
        "\n",
        "- 컴파일:\n",
        "  - optimizer='adam',\n",
        "  - loss='sparse_categorical_crossentropy',\n",
        "  - metrics=['accuracy']\n",
        "\n",
        "- epochs=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcSFz3JoCc2O",
        "outputId": "818ef735-29c2-496c-ea44-38fb462b372d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8745 - loss: 0.4365\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9631 - loss: 0.1250\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9764 - loss: 0.0795\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9821 - loss: 0.0580\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0466\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9739 - loss: 0.0880\n",
            "\n",
            "Test accuracy: 0.9781000018119812\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Input\n",
        "\n",
        "# MINST 데이터셋 로드\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# 데이터 정규화\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Sequential 모델 정의\n",
        "model = Sequential([\n",
        "    Input(shape=(28, 28)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=32)\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "Kjt8GMapCc0W",
        "outputId": "9ffc103b-55fa-4d12-9b51-10ac75ba66bc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">305,312</span> (1.16 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m305,312\u001b[0m (1.16 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,542</span> (795.09 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m203,542\u001b[0m (795.09 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ1fzoe4hEtP"
      },
      "source": [
        "각 레이어의 파라미터 개수 계산\n",
        "- Input 레이어: 파라미터가 없습니다.\n",
        "\n",
        "- Flatten 레이어: 파라미터가 없습니다. 입력 형태를 (28, 28)에서 (784,)로 변환합니다.\n",
        "\n",
        "- 첫 번째 Dense 레이어: 입력 뉴런 784개, 출력 뉴런 128개\n",
        "  - 파라미터 개수 = 784 * 128 + 128 = 100,480\n",
        "  - 각 입력 뉴런이 각 출력 뉴런과 연결되므로, 총 가중치 파라미터 수는 784 x 128이고 각 출력 뉴런마다 하나의 바이어스 파라미터가 추가되어 128개 추가\n",
        "- 두 번째 Dense 레이어: 입력 뉴런 128개, 출력 뉴런 10개\n",
        "  - 파라미터 개수 = 128 * 10 + 10 = 1290"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLgu5vh0kSBw"
      },
      "source": [
        "[ 완전신경망(완전연결신경망, Fully Connected Neural Network)에서 각 층의 파라미터 수 계산 ]\n",
        "\n",
        "- 각 연결에 하나의 가중치가 있으므로, 특정 층의 가중치 수는 이전 층의 뉴런 수와 해당 층의 뉴런 수를 곱한 값과 같다.\n",
        "- 각 뉴런에는 하나의 편향이 있으므로, 특정 층의 편향 수는 해당 층의 뉴런 수와 같다.\n",
        "- 특정 층의 총 파라미터 수는 가중치 수와 편향 수의 합이다.\n",
        "\n",
        "가중치의 의미\n",
        "- 이전 층의 뉴런 수: 각 뉴런은 이전 층의 모든 뉴런으로부터 입력 신호를 받는다. 이전 층에 더 많은 뉴런이 있을수록, 현재 층의 한 뉴런이 처리해야 할 입력 신호의 수가 더 많아진다.\n",
        "- 해당 층의 뉴런 수: 해당 층에 더 많은 뉴런이 있다는 것은, 이전 층의 각 뉴런으로부터 오는 신호를 받아들이는 더 많은 처리 단위가 있다는 것을 의미.\n",
        "- 가중치의 역할: 각 가중치는 입력 신호의 중요도를 조정. 즉, 특정 입력이 해당 뉴런의 활성화에 얼마나 영향을 미치는지 결정하는 역할을 한다. 가중치는 학습 과정에서 조정되며, 신경망이 훈련 데이터로부터 패턴을 학습하는 방식을 결정.\n",
        "\n",
        "가중치 수 계산\n",
        "- 신경망에서 정보가 전달되는 방식과 학습이 어떻게 이루어지는지를 나타낸다. 각 가중치는 이전 층의 특정 뉴런과 현재 층의 특정 뉴런 사이의 연결 강도를 나타내며 이전 층의 뉴런 수와 해당 층의 뉴런 수를 곱하는 것은 모든 가능한 연결을 고려하여 이들 간의 관계를 정량화하는 방법이다.\n",
        "- 계산 과정을 통해 각 연결마다 하나의 고유한 가중치가 할당"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvtwX7k5lj_Y"
      },
      "source": [
        "[ 픽셀(pixel) ]\n",
        "- 디지털 이미지를 구성하는 기본 단위. 단어 \"픽셀\"은 \"Picture Element\"의 줄임말로, 이미지를 구성하는 가장 작은 단일 색상의 점을 의미. 각 픽셀은 특정 색상과 밝기 값을 가지며, 이러한 픽셀들이 모여 전체 이미지를 형성\n",
        "- 색상과 밝기: 컬러 이미지에서 각 픽셀은 일반적으로 빨강(Red), 초록(Green), 파랑(Blue)의 세 가지 색상 채널 값을 가지며, 이를 RGB 값이라고 한다. 각 채널의 값은 보통 0에서 255 사이의 정수로 표현되며, 이 값들의 조합을 통해 다양한 색상을 나타낸다. 그레이스케일 이미지에서는 단일 채널만 사용하여 밝기를 표현하며, 0은 검은색, 255는 흰색을 의미하고, 그 사이의 값은 다양한 회색 음영을 나타낸다.\n",
        "- 해상도: 이미지의 해상도는 이미지의 세부 사항과 선명도를 결정하는 중요한 요소입니다. 해상도가 높은 이미지는 더 많은 픽셀을 가지며, 따라서 더 세밀한 디테일을 표현할 수 있다. 예를 들어, 1920x1080 해상도의 이미지는 가로 1920픽셀, 세로 1080픽셀로 구성되어 있다.\n",
        "- 디지털 표현: 디지털 이미지 처리, 컴퓨터 그래픽, 디지털 카메라 촬영과 같은 분야에서 픽셀은 기본적인 작업 단위로 사용되며 이미지의 품질, 색상 처리, 이미지 분석 등은 모두 픽셀 데이터를 기반으로 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrMUOjfnpoy3"
      },
      "source": [
        "[ Mnist데이터셋 ]\n",
        "\n",
        "- 입력 크기가 (28, 28)인 것은 각 이미지가 28픽셀의 너비와 28픽셀의 높이를 가진 2차원 그레이스케일 이미지라는 것을 의미\n",
        "- 각 이미지는 단일 색상 채널(그레이스케일)을 가지며, 픽셀 값은 일반적으로 0(완전 검정)에서 255(완전 백색) 사이의 값을 가진다. 따라서, 각 이미지는 28x28=784개의 픽셀로 구성되며, 각 픽셀은 해당 위치에서의 밝기 또는 색상 강도를 나타낸다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATm3v2_fCcx-",
        "outputId": "d12dca41-36ae-4ebd-ced3-ed6ad03310d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "Nu8SjuuZCcwP",
        "outputId": "198d5abe-24b2-4074-a95c-2a2231e96bb8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-e37decec-e19b-4a5f-9df8-8a27bbfddc8e\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-e37decec-e19b-4a5f-9df8-8a27bbfddc8e button').onclick = (e) => {\n",
              "        document.querySelector('#id-e37decec-e19b-4a5f-9df8-8a27bbfddc8e').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-e37decec-e19b-4a5f-9df8-8a27bbfddc8e button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ],
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "PJgToRdPCcuG",
        "outputId": "d65a9059-0a75-4f77-c9fc-2d36c94cd09d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGEAAABhCAYAAADGBs+jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAOeklEQVR4nO2d2W8T19uAn7E9tmfxMrHj2IlJIE2CSBVUAa16AVIvUKX+r5X6B1RVpSK16kUpJQ1bQiBNguN9G4+XGdvfRXVOAyXfj7YJHiM/N0TB2ON55mzved+DMh6Px8yYKIFJX8CMmQRfMJPgA2YSfMBMgg+YSfABMwk+YCbBB8wk+IDQu75QUZSLvI4PkncNRsxagg+YSfABMwk+YCbBB8wk+ICZBB8wk+ADZhJ8wEyCD5hJ8AEzCT7gnWNHHwqKorw1pvO/YmMXmZQydRIURSEQCBAIBM68cZqmMT8/j67rKIoi/004HCYSidDv9zk+PqZSqWCaJktLS5imSSwWI5lMEgqFGI/HjMdjBoMBxWKRRqNBp9OhUCjgOM65fqepkhAI/Nl7hkIhIpHImRIWFha4efMmmUxG3vxAIEAymSSZTNJsNvn22295+PAh+Xyeu3fvks/nyefzXLt2DU3TGA6HDIdDWq0WP//8M7u7uxwfH3Pv3r0PT8LbbuTpp1z8LJ5mRVEIh8Poui6lvEk8HiedTpNOp1FVFVVVCQQCWJZFMpkkHA6TSCTQNI14PM78/DzZbJbFxUUuXbqEpml4nofruhiGgWVZmKaJpmlnfuZ/YaISgsEg0WiUUCj02o2OxWLE43FUVSWZTGIYBoFAAFVVCQaDWJbF4uIi4XD4re9rmibLy8uYpomiKASDQfl5gUAA0zS5desWyWSSXC7H9evXyeVyxGIxRqMRg8GAdrtNu92mXq9zfHzM4eEhpVKJwWBw7vdh4hIMw5DdRSAQIBQKsbi4SC6XQ9d1lpeXSafThEIhNE0jGAxy6dIlNjc30TTtzPcWYgXj8ZhOp4Nt2/R6PUajEcvLy6RSKba2tkilUgyHQzzPo9/v02w2KZfL1Go1KaHRaNDv98/9PkxEQjAYlAIymQymaUoBwWCQbDbLwsIC0WiUdDpNKpWS40AoFCKRSGAYBtFo9J0/czQa4bou7XabXq9Hr9fDdV16vR7NZhNFUXBdl8FggOd5VCoVKpUKjUZDDspC3nnz3iWI7sQwDFZWVvjqq6/I5/OEw2HZInRdJxqNoqoqhmEQiUQIBAIEg0EURcEwDFRVfefPHI/HeJ7H3t4e9+/fp9fr0Wq1cByHaDTK48ePiUQi9Ho9Op0Ow+FQdkeO47C7u0uhUGAwGHwYLUG0AMuyWF5e5vbt23z88ceoqko0Gr2QgQ/A8zyKxSLb29v0ej0GgwGu6wJ/Dv6j0Yher0e73cbzPNlaBoMBlUqFVqt1IdcFE5AgnkrxBT3Pw/M8OXj+UwaDAYPBgPF4zGg0YjweEwwG5fghfj8ajWi325TLZbrdLq7r/q1rES1BDM6nr+8iee8SRqORbPLNZhPbtnEcB0VR/t+B9qz3EgPoaDSi3+/jeR6maZLP5zEMg9FoJKUfHR3x66+/4jiOXIy9+X7D4fA1ceKhuUgm0hJc10VRFPr9Pq7r4rounuf949DAeDym3+9j2/ZrrWs4HJLJZIhGo/Kmep6HbdtUKpVzX2z9VybWHQHU63UeP36M67pYlkUulyMcDsv+WFVV8vk8qVTqtfcYDAZ0u136/T47Ozs8ePCAwWAgZzzxeJznz58Ti8WIxWKkUikGgwGNRuNCY0D/lolIEINisVjkxx9/ZG9vj2w2y8bGBuFwmGq1SqVSIR6Pc/fu3b9J6Ha7lEolWq0W9+7d45tvvqHb7co+3DAMstkshmGwtrbGjRs3CAaDlEqlC5li/lcmsk4Q/XG/36fRaMhQRK1WIxwOUy6XKZfLDAYDOp0Oruu+FrTzPA/Hceh0OtTrdUqlkpQwHA6xbZvxeIymaZimSbVaJRwO0+12Zy3hTXq9HoeHh3JhdHJyQiAQoN1u02q1mJubY3l5GVVVicViLC0tYRgGlUqF3377jWq1yuHhoRxbxFPuui7NZhPHcXj69CmO4xAMBtnb22M4HE7yK7+ViUrodrscHR3JlqBpmhywB4MBc3NzXL58mWg0yvz8PJZloes61WqVhw8fcnJywtHRkZwVCTzPo9lsAlCr1djf3weQkVG/MfEo6umnVwTxxIzJdV0pRMxyREAuEokQjUbPXF+IbsevN/40E5cgGA6HMkIp5udvLuyEsFQqxfXr1+UAvrOzIyVNI76R8LZFkfidmPUICbFYjJWVFRKJBJZl/evVtl/wjYS34XmeHHwVRaFer2OaplwVj0YjkskkiUQCVVXlDGna8LWEbrfL9vY2BwcHXL16lUuXLuG6LqZpsri4SCaTYW1tjY2NDZrNJoeHh1Sr1Ulf9j/G1xKGwyG1Wo1ms0ksFpM/R6NRDMNgPB6TSCRIJpOMx2PC4fCZ2RR+xtcSxuOxHHAbjQbb29s0Gg02NzdlbGhxcZFbt27RbreZn5/n5OQE13VxHAfXdWm1WpTL5QsPwv0XfC0B/hwXFEWhWCzy/fffE4/H6XQ6bG1tEQ6H2djYIJPJ4DgO+/v7FItFOp0Or169wnEcnj9/TrvdxrbtSX+VM/G9BPgr3tRqtWQgrtPpYJomqqpiWRaaptFutwGwbVtuZVYqFSKRiFxriBmWn7qsqZAAyC3HXq/Hs2fP+O6770in06yurnLlyhWZYZHJZOj3+6yurjIYDMhmswAyxlQqlRgOh39bZU+SqZEg9gMURWF3d5fvv/8ey7L48ssvWVtbIxqNkkwm5ZpBbMxYlkW/36dSqfDo0aPXAn0zCf+C06mJjUYDgHK5TLFYRNd1EomETApTVRVFUTBNk3Q6jaIopNNpLMuS+w6u60pZk2SqJAgajQa7u7uyr9/f3yeZTHLjxg1WV1fRdZ2FhQV0XWdxcZE7d+7gOA7ZbJZMJkOj0eDhw4ccHBzIsPgk40tTKcFxHBzHIRAIyEhsKpXCMAx0XSeZTMqNIMuysCxLZlaMx2MZNi+Xy/T7fXq93kzCv0V0TbZtEwqF+OOPP9A0Dcuy5EIuHo+TSqVk15TNZgmHw1y5ckV2a6fTXyaB8q6nQfr1bAtVVQmFQoTDYRYWFuRNv3btGpZlsbW1xRdffCHXF6IVPXr0iOPjY/b29vj66695+fLluV/bu06Dp7olAK/tO7iui6qqVCoVQqEQc3NzZDIZueAzTRPTNOn1ejiOg6Zp9Ho9dF2f6HeYegmC06HwTqfD8fExzWaTtbU1ufUpNo2CwSDxeJzxeMzCwgILCwtUq1W63S62bb/32dIHJeF0q2i324RCIdbX1+n3+3JXDv7M2BbbpZ1Oh8uXL9PtdimXy3ID6X0y9RLE0w3IjAzBWSEKRVFk6rwoIhEZ4ZMY+6ZagqIo6LouaxwymQyJRIJIJEIikSAcDvPZZ5/J1Htxg0UIxHEcyuUyr1694ujoSGbyvW+mXoJhGKTTaUzTZHNzk3w+L4sBY7EY+XxeFhAKRqMRtm3TaDQolUpSgsg/fd9MjYTTNWsijT4UCpHJZFhYWJAFJ/Pz8xiGQSqVkq3kzT1osU8hcmA9z5st1t6FUChEPB4nHA6zuLjI2toapmmysrLCysoKmqaRzWblfrOu66iqiqZprxWUiFlUt9uVXdKkMzWmSoJhGGiaxtLSEp988gnJZJL19XXW19eJRCIybHEWIgAoVtq9Xo9+vz/xvCRfShClUaKqJxKJEIvFZEXm6uoqS0tLxONxkskkkUhEznDeRKTMiJpkkR65t7dHoVDgxYsXdLvdCXzLv/ClBJFdp+s66+vrMvp548YN5ufnmZubI5fLydeJMqu35R+JGZDjOGxvb7Ozs0O73ebJkyccHx/LDO9J4jsJYg4fiUTQNI1UKkUul2NpaYmNjQ2Z8v4uSV+nA3y2bVMoFNjd3aXZbEoJfmCiEsRMRxx9ICo2L1++zPLyMrFYjI2NDXK5HMlkknQ6LUtn31xUiTKsfr+P4zgUi0X558uXL+l0Ouzt7XFwcEC32/VVtc7Ei8nF7EUchaDrOnfu3OH27dsy9Cy2LSORiFzVvlnl6XketVqNer3OyckJP/30E8VikaOjI5keL/YORIjDL7x3CaK7CQaDqKoqMybEIGsYhjxrQsz3Y7HYa+9xulJTFPuJeFGj0aBWq1EqlSgUChQKBU5OTnxbIALvUUIoFCIUCqHrOteuXWNpaQlN05ibmyMajZJIJEin00QiET766CMymQyqqr71/Iputys3Y46Pj2WO0YsXLyiVSjSbTfb392k2m7RaLbmX7Ffeq4RoNIplWXz66afcvHkT0zTJ5XIYhkEsFsOyLHmIyOnTXd5E9PW2bXP//n3u379Pq9WS005xPsXpclg/c+4SRHcjMh5EPy5CCJZlyWmmruvE43H5d6IA/E1EmEHsBVerVQqFArZtUyqVqFar8vCQbrcrz7Hw89N/mnOXEIlESKVScmV79epVDMNgbm5ODrxixiMWY2J8eNuRCiJrrl6v8/TpU+r1Ont7e/zyyy+ykLxUKsmMO3Hzp0UAXIAEcQpLLBZjdXWVzz//XJ4rJDbZxdP/vzg98Nq2zf7+PoVCgd9//50ffviBZrMpT2aZZs5dgpjpWJYlj8lJJpOYpikjn6LLEd2GKJUSxx3AX4G2Wq2GbduUy2V2d3epVCoyVeV0buk0c+4SdF1nbW2NpaUlNjc32draktFPkRUnJLiuS71ep9frUSqVODg4kFuR4/EY27Z58OABL1++lOEFsRhrtVoTj36eFxfSHYmZjjhzLh6P/+11p0PKjuPQaDQoFApyPj8ajWi1Wuzs7PDkyRP52klHPC+Cc5fQ6XR49uwZ1WqVYrHIq1evzjyh63S6e61Wkwc7iae70+lQqVReK6H9EDn35C8RigiFQnKKeta/PX2kjdjpOn054vic0ymM08S7Xu/UZ+D5mdn/LjVFzCT4gJkEHzCT4ANmEnzATIIPeOfF2rTN0aeJWUvwATMJPmAmwQfMJPiAmQQfMJPgA2YSfMBMgg+YSfAB/wc7abIZVdu8XAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image_data = train_images[0]\n",
        "\n",
        "plt.figure(figsize=(1,1))\n",
        "plt.imshow(image_data, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YucuApe8r7U3",
        "outputId": "df7769dc-fc43-487a-c916-39f33d3a5c02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images[1].reshape(784,).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmEuGoptry0U"
      },
      "source": [
        "MNIST 데이터세트의 모양을 (60000, 28, 28)에서 (60000, 784)로 변경하는 이유\n",
        "- 기계 학습의 일반적인 전처리 단계이며, 특히 완전히 연결된(밀집된) 신경망의 맥락에서 필요하며 이 프로세스를 이미지 \"평탄화\"라고 한다.\n",
        "\n",
        "[ 주요 이유 ]\n",
        "- 신경망의 입력 형식: 신경망의 완전 연결된 레이어에서는 입력이 1D 벡터일 것으로 예상. 각 입력 뉴런은 다음 레이어의 모든 출력 뉴런에 연결.\n",
        "- 이미지의 원래 2D 구조(28x28픽셀)는 공간 정보를 2차원으로 표현하기 때문에 이러한 기대에 맞지 않다. 이미지를 1D 벡터(이 경우 784개 요소)로 평면화하면 각 픽셀이 네트워크에 제공될 수 있는 개별 특징이 된다.\n",
        "- 단순화: 평면화는 정보 손실 없이 데이터 구조를 단순화. 각 픽셀 값은 여전히 ​​전체 입력에 기여하지만 네트워크 계층에서 수행되는 수학적 연산(예: 내적)과 호환되는 형식.\n",
        "- 네트워크 아키텍처와의 호환성: 대부분의 기본 신경망 아키텍처, 특히 입문 목적이나 간단한 작업에 사용되는 아키텍처는 다차원 데이터가 아닌 기능 벡터로 작동하도록 설계. CNN(컨벌루션 신경망)은 다차원 데이터를 직접 처리할 수 있지만(픽셀 간 공간 계층 보존) 완전 연결된 네트워크는 본질적으로 이러한 데이터를 처리하지 않는다.\n",
        "- 효율성: 평면화된 이미지로 작업하는 것은 때때로 특정 작업에 대해 계산적으로 더 효율적일 수 있다. 특히 신경망에서 데이터 배치를 처리하기 위해 행렬 곱셈을 사용할 때 더욱 그렇다.\n",
        "- 그러나 병합하면 픽셀 간의 공간적 관계가 삭제된다는 점에 유의하는 것이 중요. 이는 이미지 인식이나 객체 위치 파악과 같이 픽셀의 공간적 배열이 중요한 작업에는 적합하지 않다. 이러한 작업의 경우 CNN(컨벌루션 신경망)이 공간 계층을 유지하면서 2D 이미지를 처리할 수 있어 네트워크가 픽셀 배열을 기반으로 더 복잡한 패턴을 학습할 수 있으므로 더 적합하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgpOi0QOtHce"
      },
      "source": [
        "[ 레이블이 원-핫 인코딩되지 않은 이유 ]\n",
        "\n",
        "모델의 손실 함수(loss function)로 'sparse_categorical_crossentropy'가 사용되기 때문. TensorFlow와 Keras에서 두 가지 유형의 크로스엔트로피 손실 함수를 제공하며, 각각은 다음과 같은 경우에 사용된다:\n",
        "\n",
        "- 'sparse_categorical_crossentropy': 이 손실 함수는 레이블이 정수 형태로 제공될 때 사용. 즉, 각 샘플에 대해 단일 정수로 클래스 레이블이 지정되며, 이 경우 원-핫 인코딩을 할 필요가 없다. 이 함수는 내부적으로 정수 레이블을 적절한 원-핫 인코딩 형태로 변환하여 처리.\n",
        "\n",
        "- 'categorical_crossentropy': 이 손실 함수는 레이블이 원-핫 인코딩된 형태로 제공될 때 사용. 각 샘플의 레이블이 벡터이며, 벡터의 각 원소는 해당 클래스의 소속 여부를 나타낸다(클래스에 속하면 1, 아니면 0)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEt09V0jtKVt"
      },
      "source": [
        "### Convolutional Neural Network (CNN)\n",
        "CNN은 컨벌루션 레이어와 풀링 레이어를 사용하여 이미지의 공간 계층 구조를 캡처할 수 있기 때문에 이미지 처리 작업에 특히 적합\n",
        "\n",
        "[ CNN 아키텍처 ]\n",
        "- 컨볼루션 레이어(Conv2D): 이 레이어는 컨볼루션 작업을 수행하여 이미지에서 공간 특징을 캡처.\n",
        "- 풀링 레이어 (MaxPooling2D): 이 레이어는 다음 컨벌루션 레이어에 대한 입력 볼륨의 공간 크기(높이 및 너비)를 줄인다. 이는 계산 부하와 메모리 사용량을 줄이고 표현의 추상화된 형식을 제공하여 과적합을 줄이는 데 사용.\n",
        "- 밀집 레이어(완전 연결 레이어): 여러 컨볼루션 및 풀링 레이어 이후 신경망의 상위 수준 추론은 컨볼루션 레이어에서 추출하고 평면화한 특징을 기반으로 분류를 수행하는 Dense 레이어를 통해 수행.\n",
        "- 모델은 컨벌루션 레이어와 밀집 레이어에 'relu' 활성화를 사용(10자리 클래스에 대한 확률을 출력하기 위해 'softmax'를 사용하는 출력 레이어 제외). 다중 클래스 분류 작업에 적합한 adam 최적화 프로그램과 categorical_crossentropy 손실 함수로 컴파일.\n",
        "\n",
        "이 CNN 아키텍처를 사용하면 MNIST와 같은 이미지 분류 작업에서 높은 정확도를 달성하는 데 중요한 이미지 내 공간 관계를 활용할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q6Y9ldvCcr-",
        "outputId": "1a74c289-f240-45ba-a356-9baca701e601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9099 - loss: 0.3002\n",
            "Epoch 2/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9884 - loss: 0.0388\n",
            "Epoch 3/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0227\n",
            "Epoch 4/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9946 - loss: 0.0163\n",
            "Epoch 5/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9960 - loss: 0.0117\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9872 - loss: 0.0408\n",
            "Test accuracy: 0.9908000230789185\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.InputLayer(shape=(28, 28, 1)))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "2M7XvBYsCcp2",
        "outputId": "3c0d4d52-9f78-4307-b98d-6ee7220e9238"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">409,664</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m36,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6400\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │         \u001b[38;5;34m409,664\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,398,176</span> (5.33 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,398,176\u001b[0m (5.33 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">466,058</span> (1.78 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m466,058\u001b[0m (1.78 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">932,118</span> (3.56 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m932,118\u001b[0m (3.56 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRCDEgU8zXXd"
      },
      "source": [
        "Task1_0806. 다음 사항을 준수하여 Fashion MNINS 데이터셋에 대하여 Sequential 방식으로 모델 생성 및 평가를 수행하세요.\n",
        "- 입력 계층: layers.InputLayer(input_shape=(28*28,))\n",
        "- 첫 번째 Dense 계층 : 출력 512, activation='relu'\n",
        "- 두 번째 Dense 계층 : 출력 256, activation='relu'\n",
        "- 출력 계층 : 출력 10, activation='softmax'\n",
        "- 모델 컴파일 : optimizer='adam', loss='categorical_crossentropy',         metrics=['accuracy']\n",
        "- 모델 학습 : epochs=10, batch_size=64\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Fashion MNIST 데이터셋 로드\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxiuBdqiCcn-",
        "outputId": "34c2d4f6-d9f3-477d-cf62-fc43b54cd029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7879 - loss: 0.6008\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8681 - loss: 0.3603\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8827 - loss: 0.3188\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8914 - loss: 0.2921\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8953 - loss: 0.2787\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9021 - loss: 0.2611\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.2402\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2371\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2244\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2152\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8893 - loss: 0.3399\n",
            "Test accuracy: 0.8895000219345093\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Fashion MNIST 데이터셋 로드\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# 데이터 전처리: 이미지 정규화 및 평탄화\n",
        "train_images = train_images.reshape((60000, 28 * 28)) / 255.0\n",
        "test_images = test_images.reshape((10000, 28 * 28)) / 255.0\n",
        "\n",
        "# 모델 생성\n",
        "model = models.Sequential([\n",
        "    layers.InputLayer(input_shape=(28*28,)),  # 입력 계층\n",
        "    layers.Dense(512, activation='relu'),     # 첫 번째 Dense 계층\n",
        "    layers.Dense(256, activation='relu'),     # 두 번째 Dense 계층\n",
        "    layers.Dense(10, activation='softmax')    # 출력 계층\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(train_images, to_categorical(train_labels), epochs=10, batch_size=64)\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(test_images, to_categorical(test_labels))\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "HtDxwhGoCcl-",
        "outputId": "57c1eeb8-c86d-4dfa-80ac-1caf3eeeaaf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train images shape: (60000, 28, 28)\n",
            "Shape of the selected image: (28, 28)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Fashion MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Print the shape of train_images to verify its dimensions\n",
        "print(\"Train images shape:\", train_images.shape)\n",
        "\n",
        "# Since train_images is already in 28x28 shape, reshape isn't necessary\n",
        "# Select the first image\n",
        "image_data = train_images[0]\n",
        "\n",
        "# Check the shape of the selected image\n",
        "print(\"Shape of the selected image:\", image_data.shape)\n",
        "\n",
        "# Display the image using matplotlib\n",
        "plt.figure(figsize=(2, 2))\n",
        "plt.imshow(image_data, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ooypg7sQCcf-",
        "outputId": "c56f2f60-b028-42b4-d31f-894d7fa7dde0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train images shape: (60000, 28, 28, 1)\n",
            "Train labels shape: (60000, 10, 2, 10, 2, 2, 2)\n"
          ]
        }
      ],
      "source": [
        "print(\"Train images shape:\", train_images.shape)\n",
        "print(\"Train labels shape:\", train_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfAU1R1GCcdd",
        "outputId": "83d3f4e9-ca3b-4d9a-8078-c442e52aa80c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train images shape: (60000, 28, 28, 1)\n",
            "Train labels shape: (60000, 10)\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7137 - loss: 0.7931\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8759 - loss: 0.3447\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8897 - loss: 0.2974\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9024 - loss: 0.2653\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.2351\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9211 - loss: 0.2132\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9280 - loss: 0.1942\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9334 - loss: 0.1791\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9367 - loss: 0.1684\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9422 - loss: 0.1556\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.2726\n",
            "Test accuracy: 0.9129999876022339\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fashion MNIST 데이터셋 로드\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# 데이터 정규화\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# 레이블을 원핫인코딩\n",
        "train_labels = to_categorical(train_labels, num_classes=10)\n",
        "test_labels = to_categorical(test_labels, num_classes=10)\n",
        "\n",
        "# 이미지 차원 변경\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "\n",
        "# 학습 데이터와 레이블 형상 출력\n",
        "print(\"Train images shape:\", train_images.shape)\n",
        "print(\"Train labels shape:\", train_labels.shape)\n",
        "\n",
        "# 모델 정의\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=64)\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRsEGLRjYG2n"
      },
      "source": [
        "함수형 API\n",
        "\n",
        "Keras 내장 데이터셋인 Fashion MNIST를 사용하여 분류 모델을 학습하고 평가하세요.\n",
        "- Fashion MNIST는 기존의 MNIST 데이터셋과 같은 형식을 가지고 있지만, 손으로 쓴 숫자 대신에 10가지 범주의 패션 아이템(예: 티셔츠, 바지, 신발 등)의 이미지로 구성\n",
        "- 입력층, 두 개의 은닉층, 그리고 Softmax 활성화 함수를 사용하는 출력층으로 구성\n",
        "- 모델은 Adam 최적화 알고리즘과 categorical_crossentropy 손실 함수를 사용하여 컴파일\n",
        "- 학습 과정에서 정확도를 평가 지표로 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "B1NXN_e8CcZ-",
        "outputId": "98c90bfc-dd32-467c-c280-0abd945731e5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_15\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_15\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_layer (\u001b[38;5;33mFlatten\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m401,920\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m2,570\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">535,818</span> (2.04 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m535,818\u001b[0m (2.04 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">535,818</span> (2.04 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m535,818\u001b[0m (2.04 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7688 - loss: 0.6696 - val_accuracy: 0.8454 - val_loss: 0.4231\n",
            "Epoch 2/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8627 - loss: 0.3724 - val_accuracy: 0.8708 - val_loss: 0.3579\n",
            "Epoch 3/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8797 - loss: 0.3313 - val_accuracy: 0.8822 - val_loss: 0.3326\n",
            "Epoch 4/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8896 - loss: 0.3001 - val_accuracy: 0.8772 - val_loss: 0.3369\n",
            "Epoch 5/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8950 - loss: 0.2839 - val_accuracy: 0.8834 - val_loss: 0.3248\n",
            "Epoch 6/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8991 - loss: 0.2667 - val_accuracy: 0.8893 - val_loss: 0.3089\n",
            "Epoch 7/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.2571 - val_accuracy: 0.8842 - val_loss: 0.3242\n",
            "Epoch 8/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2370 - val_accuracy: 0.8825 - val_loss: 0.3373\n",
            "Epoch 9/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.2319 - val_accuracy: 0.8882 - val_loss: 0.3027\n",
            "Epoch 10/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.2158 - val_accuracy: 0.8947 - val_loss: 0.2983\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8887 - loss: 0.3262\n",
            "\n",
            "테스트 손실: 0.3271687924861908\n",
            "테스트 정확도: 0.887499988079071\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터셋 로드\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# 데이터 전처리\n",
        "# 이미지 픽셀 값을 0~1 사이로 스케일링\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# 레이블을 원핫인코딩\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# 입력 데이터의 차원\n",
        "input_shape = (28, 28, 1)  # Keep it as it is for compatibility with the data shape\n",
        "# 입력층 정의\n",
        "input_layer = Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "# Flattening layer to convert 2D input to 1D\n",
        "flatten_layer = Flatten(name='flatten_layer')(input_layer)\n",
        "\n",
        "# 완전 연결층 추가\n",
        "hidden1 = Dense(512, activation='relu', name='hidden_layer_1')(flatten_layer)\n",
        "hidden2 = Dense(256, activation='relu', name='hidden_layer_2')(hidden1)\n",
        "\n",
        "# 출력층 추가\n",
        "output_layer = Dense(10, activation='softmax', name='output_layer')(hidden2)\n",
        "\n",
        "# 모델 정의\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 요약 출력\n",
        "model.summary()\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('\\n테스트 손실:', test_loss)\n",
        "print('테스트 정확도:', test_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2fxSgaibnM-"
      },
      "source": [
        "Q. MNIST 데이터셋에 대하여 함수형 API를 사용하여 같은 아키텍처의 신경망을 구성하여 학습 및 평가를 수행하세요.\n",
        "- 입력층 : shape=(28, 28)\n",
        "- 은닉층 1 : 128, relu\n",
        "- 은닉층 2 : 64, relu\n",
        "- 출력층 : 10, softmax\n",
        "- 비용함수 : sparse_categorical_crossentro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "xApHTqMcCcXW",
        "outputId": "43d1aaf6-3997-4c55-f328-007f12ac144e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_17\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_layer (\u001b[38;5;33mFlatten\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7193 - loss: 11.0031 - val_accuracy: 0.8912 - val_loss: 0.8009\n",
            "Epoch 2/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9011 - loss: 0.6183 - val_accuracy: 0.9067 - val_loss: 0.5043\n",
            "Epoch 3/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9301 - loss: 0.3348 - val_accuracy: 0.9245 - val_loss: 0.3997\n",
            "Epoch 4/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9471 - loss: 0.2201 - val_accuracy: 0.9334 - val_loss: 0.3447\n",
            "Epoch 5/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9544 - loss: 0.1716 - val_accuracy: 0.9417 - val_loss: 0.3232\n",
            "Epoch 6/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9607 - loss: 0.1486 - val_accuracy: 0.9383 - val_loss: 0.3084\n",
            "Epoch 7/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9669 - loss: 0.1191 - val_accuracy: 0.9518 - val_loss: 0.2676\n",
            "Epoch 8/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.1041 - val_accuracy: 0.9430 - val_loss: 0.2984\n",
            "Epoch 9/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9731 - loss: 0.0973 - val_accuracy: 0.9559 - val_loss: 0.2566\n",
            "Epoch 10/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9760 - loss: 0.0853 - val_accuracy: 0.9531 - val_loss: 0.2558\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9409 - loss: 0.3100\n",
            "\n",
            "테스트 손실: 0.26253968477249146\n",
            "테스트 정확도: 0.95169997215271\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input\n",
        "\n",
        "# 데이터셋 로드\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# 데이터 전처리\n",
        "# 이미지 픽셀 값을 0~1 사이로 스케일링\n",
        "train_images = train_images.reshape((60000, 28 * 28)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28)).astype('float32') / 255\n",
        "\n",
        "# 입력 데이터의 차원\n",
        "input_shape = (784,)\n",
        "\n",
        "# 입력층 정의\n",
        "input_layer = Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "# 완전 연결층 추가\n",
        "hidden1 = Dense(128, activation='relu', name='hidden_layer_1')(input_layer)\n",
        "hidden2 = Dense(64, activation='relu', name='hidden_layer_2')(hidden1)\n",
        "\n",
        "# 출력층 추가\n",
        "output_layer = Dense(10, activation='softmax', name='output_layer')(hidden2)\n",
        "\n",
        "# 모델 정의\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 요약 출력\n",
        "model.summary()\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('\\n테스트 손실:', test_loss)\n",
        "print('테스트 정확도:', test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "TnaTTEpfCcVm",
        "outputId": "aa8983c4-f9ef-4849-95b3-89f64708660d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_18\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_18\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8132 - loss: 0.6697 - val_accuracy: 0.9519 - val_loss: 0.1730\n",
            "Epoch 2/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9562 - loss: 0.1509 - val_accuracy: 0.9635 - val_loss: 0.1243\n",
            "Epoch 3/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.1013 - val_accuracy: 0.9677 - val_loss: 0.1072\n",
            "Epoch 4/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9789 - loss: 0.0734 - val_accuracy: 0.9654 - val_loss: 0.1130\n",
            "Epoch 5/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9824 - loss: 0.0592 - val_accuracy: 0.9713 - val_loss: 0.0928\n",
            "Epoch 6/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9861 - loss: 0.0462 - val_accuracy: 0.9726 - val_loss: 0.0910\n",
            "Epoch 7/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.0384 - val_accuracy: 0.9720 - val_loss: 0.0914\n",
            "Epoch 8/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0277 - val_accuracy: 0.9727 - val_loss: 0.0885\n",
            "Epoch 9/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0231 - val_accuracy: 0.9727 - val_loss: 0.0956\n",
            "Epoch 10/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9938 - loss: 0.0201 - val_accuracy: 0.9738 - val_loss: 0.0951\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 0.0934\n",
            "\n",
            "테스트 손실: 0.07853495329618454\n",
            "테스트 정확도: 0.9765999913215637\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input\n",
        "\n",
        "# 데이터셋 로드\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# 데이터 전처리\n",
        "# 이미지 픽셀 값을 0~1 사이로 스케일링\n",
        "train_images = train_images.reshape((60000, 28 * 28)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28)).astype('float32') / 255\n",
        "\n",
        "# 입력 데이터의 차원\n",
        "input_shape = (784,)\n",
        "\n",
        "# 입력층 정의\n",
        "input_layer = Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "# 완전 연결층 추가\n",
        "hidden1 = Dense(128, activation='relu', name='hidden_layer_1')(input_layer)\n",
        "hidden2 = Dense(64, activation='relu', name='hidden_layer_2')(hidden1)\n",
        "\n",
        "# 출력층 추가\n",
        "output_layer = Dense(10, activation='softmax', name='output_layer')(hidden2)\n",
        "\n",
        "# 모델 정의\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 요약 출력\n",
        "model.summary()\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('\\n테스트 손실:', test_loss)\n",
        "print('테스트 정확도:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "lA4bP_fZCcTm",
        "outputId": "c4715e0e-848c-42a9-ab17-509052c8dcb7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_19\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_19\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8091 - loss: 0.6802 - val_accuracy: 0.9524 - val_loss: 0.1730\n",
            "Epoch 2/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9534 - loss: 0.1564 - val_accuracy: 0.9603 - val_loss: 0.1347\n",
            "Epoch 3/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9675 - loss: 0.1087 - val_accuracy: 0.9672 - val_loss: 0.1118\n",
            "Epoch 4/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.0795 - val_accuracy: 0.9679 - val_loss: 0.1062\n",
            "Epoch 5/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9815 - loss: 0.0618 - val_accuracy: 0.9706 - val_loss: 0.0979\n",
            "Epoch 6/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9870 - loss: 0.0464 - val_accuracy: 0.9715 - val_loss: 0.0969\n",
            "Epoch 7/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0396 - val_accuracy: 0.9740 - val_loss: 0.0913\n",
            "Epoch 8/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0300 - val_accuracy: 0.9723 - val_loss: 0.0949\n",
            "Epoch 9/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0275 - val_accuracy: 0.9737 - val_loss: 0.0940\n",
            "Epoch 10/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0227 - val_accuracy: 0.9727 - val_loss: 0.0955\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 0.0960\n",
            "\n",
            "테스트 손실: 0.08290399610996246\n",
            "테스트 정확도: 0.9753000140190125\n"
          ]
        }
      ],
      "source": [
        "# Q. MNIST 데이터셋에 대하여 함수형 API를 사용하여 같은 아키텍처의 신경망을 구성하여 학습 및 평가를 수행하세요.\n",
        "# 입력층 : shape=(28, 28)\n",
        "# 은닉층 1 : 128, relu\n",
        "# 은닉층 2 : 64, relu\n",
        "# 출력층 : 10, softmax\n",
        "# 비용함수 : sparse_categorical_crossentro\n",
        "# flatten() 함수를 사용하여 입력층을 1차원으로 변환\n",
        "\n",
        "# 데이터셋 로드\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# 데이터 전처리\n",
        "# 이미지 픽셀 값을 0~1 사이로 스케일링\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# 입력층 정의\n",
        "input_layer = Input(shape=(28, 28), name='input_layer')\n",
        "\n",
        "# 1차원으로 변환\n",
        "flatten = Flatten(name='flatten')(input_layer)\n",
        "\n",
        "# 완전 연결층 추가\n",
        "hidden1 = Dense(128, activation='relu', name='hidden_layer_1')(flatten)\n",
        "hidden2 = Dense(64, activation='relu', name='hidden_layer_2')(hidden1)\n",
        "\n",
        "# 출력층 추가\n",
        "output_layer = Dense(10, activation='softmax', name='output_layer')(hidden2)\n",
        "\n",
        "# 모델 정의\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 요약 출력\n",
        "model.summary()\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('\\n테스트 손실:', test_loss)\n",
        "print('테스트 정확도:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86GIfsYlCcRO",
        "outputId": "53d52bd0-5258-4a45-f9f9-4837efc846e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "Predicted class: 7\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 새로운 이미지 데이터 예시\n",
        "# 실제 사용 시에는 새로운 이미지 데이터를 여기에 로드하고 전처리 해야 합니다.\n",
        "# 예를 들어, 새로운 이미지가 하나만 있는 경우, 이미지를 (28, 28) 크기로 변환하고, 255로 나누어 정규화합니다.\n",
        "new_image = test_images[0]\n",
        "# [배치 크기, 이미지 높이, 이미지 너비, 채널 수]\n",
        "new_image = np.expand_dims(new_image, axis=0)\n",
        "\n",
        "# 모델을 사용하여 예측\n",
        "predictions = model.predict(new_image)\n",
        "\n",
        "# 예측 결과 출력\n",
        "predicted_class = np.argmax(predictions, axis=1)\n",
        "print(f\"Predicted class: {predicted_class[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNt07xtVCcPV",
        "outputId": "0a0b4196-9f15-4e2b-dc1c-a8767e157660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 10)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([7])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(predictions.shape)\n",
        "predicted_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNR-w6xECcNV",
        "outputId": "e6a69ad8-564f-485d-b9ba-7f3c0d87b9d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_images[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "0RxeJckYlIhC",
        "outputId": "5b5d86cc-9e26-4fae-ef10-41220be7113a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image_data = test_images[0]\n",
        "\n",
        "plt.figure(figsize=(1,1))\n",
        "plt.imshow(image_data, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZtVLcXF7lzoC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97c34e33-21f7-47f9-d01d-0a2ac7612140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_images.shape)\n",
        "train_img = train_images.reshape((-1, 28, 28, 1))\n",
        "train_img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmteDAI5yf_0",
        "outputId": "38f6ce54-7f03-4bd4-e487-695ddc77f1ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0s4-nJplBXy"
      },
      "source": [
        "Task1_0807. MNIST 데이터셋에 대해서 함수형 API로 아래와 같이 ConvNet 레이어를 추가하여 모델을 구성하고 학습 및 평가를 수행하세요.\n",
        "\n",
        "- ConvNet은 Conv2D 3개, MaxPooling2D 2개로 구성.\n",
        "- 필터개수는 32, 64, 64개로 필터사이즈는 (3,3),\n",
        "- MaxPooling2D의 윈도우 크기는 (2,2),\n",
        "- 활성화 함수는  relu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "id": "Tx01aUagCcLe",
        "outputId": "e1f4903d-35b3-4eb9-e17a-4d30c9391fb9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1 (\u001b[38;5;33mConv2D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ maxpool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2 (\u001b[38;5;33mConv2D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ maxpool2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3 (\u001b[38;5;33mConv2D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m36,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m36,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ maxpool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ maxpool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m93,322\u001b[0m (364.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,322</span> (364.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m93,322\u001b[0m (364.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,322</span> (364.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 106ms/step - accuracy: 0.7936 - loss: 0.6814 - val_accuracy: 0.9757 - val_loss: 0.0834\n",
            "Epoch 2/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 104ms/step - accuracy: 0.9776 - loss: 0.0734 - val_accuracy: 0.9835 - val_loss: 0.0550\n",
            "Epoch 3/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 103ms/step - accuracy: 0.9843 - loss: 0.0511 - val_accuracy: 0.9861 - val_loss: 0.0491\n",
            "Epoch 4/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 103ms/step - accuracy: 0.9882 - loss: 0.0368 - val_accuracy: 0.9876 - val_loss: 0.0400\n",
            "Epoch 5/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 118ms/step - accuracy: 0.9911 - loss: 0.0274 - val_accuracy: 0.9868 - val_loss: 0.0468\n",
            "Epoch 6/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 104ms/step - accuracy: 0.9923 - loss: 0.0237 - val_accuracy: 0.9882 - val_loss: 0.0421\n",
            "Epoch 7/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 104ms/step - accuracy: 0.9951 - loss: 0.0164 - val_accuracy: 0.9874 - val_loss: 0.0421\n",
            "Epoch 8/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 103ms/step - accuracy: 0.9944 - loss: 0.0166 - val_accuracy: 0.9887 - val_loss: 0.0398\n",
            "Epoch 9/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 108ms/step - accuracy: 0.9956 - loss: 0.0133 - val_accuracy: 0.9892 - val_loss: 0.0381\n",
            "Epoch 10/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 125ms/step - accuracy: 0.9959 - loss: 0.0129 - val_accuracy: 0.9898 - val_loss: 0.0380\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9885 - loss: 0.0363\n",
            "\n",
            "테스트 손실: 0.026581164449453354\n",
            "테스트 정확도: 0.9916999936103821\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터셋 로드\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# 데이터 전처리\n",
        "# 이미지 픽셀 값을 0~1 사이로 스케일링\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# 레이블을 원핫인코딩\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# 입력층 정의\n",
        "input_layer = layers.Input(shape=(28, 28, 1), name='input_layer')\n",
        "\n",
        "# ConvNet 구성\n",
        "conv1 = layers.Conv2D(32, (3, 3), activation='relu', name='conv1')(input_layer)\n",
        "maxpool1 = layers.MaxPooling2D((2, 2), name='maxpool1')(conv1)\n",
        "conv2 = layers.Conv2D(64, (3, 3), activation='relu', name='conv2')(maxpool1)\n",
        "maxpool2 = layers.MaxPooling2D((2, 2), name='maxpool2')(conv2)\n",
        "conv3 = layers.Conv2D(64, (3, 3), activation='relu', name='conv3')(maxpool2)\n",
        "\n",
        "# Flatten\n",
        "flatten = layers.Flatten(name='flatten')(conv3)\n",
        "\n",
        "# 완전 연결층 추가\n",
        "hidden1 = layers.Dense(64, activation='relu', name='hidden_layer_1')(flatten)\n",
        "\n",
        "# 출력층 추가\n",
        "output_layer = layers.Dense(10, activation='softmax', name='output_layer')(hidden1)\n",
        "\n",
        "# 모델 정의\n",
        "model = models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 요약 출력\n",
        "model.summary()\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('\\n테스트 손실:', test_loss)\n",
        "print('테스트 정확도:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syb0fyWomjtJ"
      },
      "source": [
        "[ 선형 회귀 활성화 함수 ]\n",
        "- 선형 회귀 모델의 출력 레이어는 보통 단일 뉴런으로 구성되며 활성화 함수가 없는  형태를 취하며 이는 모델이 어떠한 범위의 값을 직접 출력할 수 있게 하기 위함이다.\n",
        "- 활성화 함수는 신경망에서 비선형성을 도입하기 위해 사용. 비선형 활성화 함수(예: ReLU, 시그모이드, 탄젠트 등)를 사용하면 신경망은 복잡한 패턴과 비선형 관계를 학습할 수 있다. 그러나 선형 회귀에서는 모델 출력이 입력 변수의 선형 조합으로 표현되어야 하므로, 비선형 활성화 함수를 사용할 필요가 없다.\n",
        "- 따라서 선형 회귀 모델의 경우, 출력 계층에 \"linear\" 활성화 함수를 명시적으로 설정하거나 (이는 입력에 대한 아무런 변환도 적용하지 않는 것과 동일), 아예 활성화 함수를 지정하지 않는 것이 일반적. Keras에서 Dense 계층을 추가할 때 activation 매개변수를 설정하지 않으면 기본적으로 \"linear\" 활성화 함수가 사용된다. 즉, 출력 뉴런의 값은 입력에 대한 선형 변환 결과이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2CI-dnqCcJe",
        "outputId": "ac3bc85f-2ddf-4d73-f00b-5e64d3a20d8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 7098.0562\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 1879.2867\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 1107.4076\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 988.7007\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 965.9626\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 957.3546\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 950.8557\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 944.7007\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 938.6299\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 932.6050\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 926.6198\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 920.6737\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 914.7661\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 908.8967\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 903.0653\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 897.2717\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 891.5156\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 885.7967\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 880.1150\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 874.4700\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 868.8615\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 863.2893\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 857.7532\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 852.2530\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 846.7885\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 841.3593\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 835.9651\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 830.6060\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 825.2815\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 819.9916\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 814.7360\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 809.5142\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 804.3262\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 799.1719\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 794.0510\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 788.9633\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 783.9085\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 778.8865\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 773.8969\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 768.9396\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 764.0144\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 759.1212\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 754.2597\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 749.4296\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 744.6307\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - loss: 739.8629\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 735.1261\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 730.4198\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 725.7441\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 721.0986\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 716.4833\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 711.8977\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 707.3419\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 702.8156\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 698.3185\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 693.8507\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 689.4117\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 685.0016\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - loss: 680.6199\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 676.2666\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 671.9415\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 667.6445\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 663.3751\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 659.1335\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 654.9194\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 650.7324\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 646.5728\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 642.4399\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 638.3339\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 634.2543\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 630.2013\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 626.1744\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 622.1738\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 618.1989\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 614.2498\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 610.3262\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 606.4281\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 602.5552\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 598.7073\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 594.8845\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 591.0864\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 587.3127\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 583.5637\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 579.8390\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 576.1381\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 572.4614\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 568.8085\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 565.1791\n",
            "Epoch 89/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 561.5734\n",
            "Epoch 90/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 557.9909\n",
            "Epoch 91/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 554.4316\n",
            "Epoch 92/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 550.8954\n",
            "Epoch 93/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 547.3821\n",
            "Epoch 94/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 543.8915\n",
            "Epoch 95/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 540.4236\n",
            "Epoch 96/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 536.9780\n",
            "Epoch 97/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 533.5549\n",
            "Epoch 98/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 530.1539\n",
            "Epoch 99/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 526.7748\n",
            "Epoch 100/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 523.4177\n",
            "Epoch 101/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 520.0823\n",
            "Epoch 102/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 516.7684\n",
            "Epoch 103/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 513.4762\n",
            "Epoch 104/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 510.2051\n",
            "Epoch 105/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 506.9553\n",
            "Epoch 106/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 503.7264\n",
            "Epoch 107/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 500.5185\n",
            "Epoch 108/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 497.3315\n",
            "Epoch 109/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 494.1649\n",
            "Epoch 110/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 491.0190\n",
            "Epoch 111/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 487.8933\n",
            "Epoch 112/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 484.7880\n",
            "Epoch 113/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 481.7027\n",
            "Epoch 114/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 478.6374\n",
            "Epoch 115/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 475.5920\n",
            "Epoch 116/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 472.5663\n",
            "Epoch 117/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 469.5602\n",
            "Epoch 118/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 466.5735\n",
            "Epoch 119/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 463.6061\n",
            "Epoch 120/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 460.6581\n",
            "Epoch 121/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 457.7289\n",
            "Epoch 122/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 454.8189\n",
            "Epoch 123/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 451.9277\n",
            "Epoch 124/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 449.0551\n",
            "Epoch 125/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 446.2013\n",
            "Epoch 126/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 443.3660\n",
            "Epoch 127/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 440.5488\n",
            "Epoch 128/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 437.7500\n",
            "Epoch 129/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 434.9692\n",
            "Epoch 130/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 432.2067\n",
            "Epoch 131/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 429.4619\n",
            "Epoch 132/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 426.7348\n",
            "Epoch 133/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 424.0254\n",
            "Epoch 134/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 421.3337\n",
            "Epoch 135/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 418.6591\n",
            "Epoch 136/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 416.0020\n",
            "Epoch 137/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 413.3623\n",
            "Epoch 138/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 410.7395\n",
            "Epoch 139/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 408.1336\n",
            "Epoch 140/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 405.5447\n",
            "Epoch 141/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - loss: 402.9725\n",
            "Epoch 142/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 400.4170\n",
            "Epoch 143/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 397.8781\n",
            "Epoch 144/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 395.3556\n",
            "Epoch 145/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 392.8493\n",
            "Epoch 146/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 390.3594\n",
            "Epoch 147/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 387.8856\n",
            "Epoch 148/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 385.4277\n",
            "Epoch 149/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 382.9859\n",
            "Epoch 150/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 380.5597\n",
            "Epoch 151/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 378.1493\n",
            "Epoch 152/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 375.7545\n",
            "Epoch 153/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 373.3753\n",
            "Epoch 154/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 371.0114\n",
            "Epoch 155/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 368.6629\n",
            "Epoch 156/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 366.3295\n",
            "Epoch 157/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 364.0112\n",
            "Epoch 158/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 361.7080\n",
            "Epoch 159/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 359.4196\n",
            "Epoch 160/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 357.1460\n",
            "Epoch 161/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 354.8874\n",
            "Epoch 162/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 352.6431\n",
            "Epoch 163/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 350.4135\n",
            "Epoch 164/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 348.1983\n",
            "Epoch 165/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 345.9975\n",
            "Epoch 166/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 343.8109\n",
            "Epoch 167/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 341.6383\n",
            "Epoch 168/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 339.4800\n",
            "Epoch 169/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 337.3356\n",
            "Epoch 170/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 335.2051\n",
            "Epoch 171/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 333.0884\n",
            "Epoch 172/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 330.9854\n",
            "Epoch 173/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 328.8959\n",
            "Epoch 174/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 326.8202\n",
            "Epoch 175/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 324.7577\n",
            "Epoch 176/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 322.7086\n",
            "Epoch 177/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 320.6728\n",
            "Epoch 178/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 318.6501\n",
            "Epoch 179/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 316.6407\n",
            "Epoch 180/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 314.6440\n",
            "Epoch 181/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 312.6605\n",
            "Epoch 182/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 310.6898\n",
            "Epoch 183/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 308.7318\n",
            "Epoch 184/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 306.7864\n",
            "Epoch 185/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 304.8539\n",
            "Epoch 186/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 302.9337\n",
            "Epoch 187/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 301.0259\n",
            "Epoch 188/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 299.1304\n",
            "Epoch 189/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 297.2473\n",
            "Epoch 190/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 295.3764\n",
            "Epoch 191/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 293.5176\n",
            "Epoch 192/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 291.6707\n",
            "Epoch 193/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 289.8360\n",
            "Epoch 194/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 288.0131\n",
            "Epoch 195/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 286.2019\n",
            "Epoch 196/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 284.4025\n",
            "Epoch 197/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 282.6147\n",
            "Epoch 198/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 280.8385\n",
            "Epoch 199/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 279.0739\n",
            "Epoch 200/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 277.3206\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ee7e82d4490>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# 텐서플로/케라스에서 실행하는 선형 회귀 모델\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 텐서 플로의 케라스 API에서 필요한 함수들을 불러옵니다.\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "x = np.array([2, 4, 6, 8])\n",
        "y = np.array([81, 93, 91, 97])\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# 출력 값, 입력 변수, 분석 방법에 맞게끔 모델을 설정합니다.\n",
        "model.add(Input(shape=(1,)))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# 오차 수정을 위해 경사 하강법을, 오차의 정도를 판단하기 위해 평균 제곱 오차를 사용합니다.\n",
        "model.compile(optimizer='sgd', loss='mse')\n",
        "\n",
        "# 오차를 최소화하는 과정을 200번 반복합니다.\n",
        "model.fit(x, y, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0VqqsJ-_CcHX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "0c4af2af-3882-49da-af59-2e4841c7481e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.scatter(x, y)\n",
        "plt.plot(x, model.predict(x), 'r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "emvjlhmxCcFe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc07434d-a414-48cf-aa0c-28511e6dbb31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7시간을 공부할 경우의 예상 점수는 95.10점입니다.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 공부 시간과 점수 데이터\n",
        "x = np.array([2, 4, 6, 8])\n",
        "y = np.array([81, 93, 91, 97])\n",
        "\n",
        "# 데이터를 2차원 배열로 변환\n",
        "x = x.reshape(-1, 1)\n",
        "\n",
        "# 모델 초기화 및 학습\n",
        "model = LinearRegression()\n",
        "model.fit(x, y)\n",
        "\n",
        "# 예측할 시간\n",
        "hour = 7\n",
        "prediction = model.predict(np.array([hour]).reshape(-1, 1))\n",
        "\n",
        "# 결과 출력\n",
        "print(\"%.f시간을 공부할 경우의 예상 점수는 %.02f점입니다.\" % (hour, prediction[0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task2_1231. house_train.csv 데이터셋으로 주택가격 예측 모델을 학습시키고 평가하세요. (Dense층 여러개로 만들기, 딥러닝으로)"
      ],
      "metadata": {
        "id": "Yx_ahvdv5aNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 주택가격 예측\n",
        "- 아이오아주 에임스 지역에서 2006년 부터 2010년까지 거래된 실제 부동산 판매 기록\n",
        "- 주거 유형, 차고, 자재 및 환경 등 80개의 서로 다른 속성을 이용해 집의 가격을 예측\n",
        "- 속성에 대한 상세 설명 : https://jse.amstat.org/v19n3/decock/DataDocumentation.txt"
      ],
      "metadata": {
        "id": "upZESLar6QQC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qpAffn0kCcDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "445552b3-27c7-47d5-ecd2-392f7aadf036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/10\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/10\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/10\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/10\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/10\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/10\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/10\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/10\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/10\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan  \n",
            "테스트 손실: nan\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# 데이터셋 로드\n",
        "df = pd.read_csv('/content/house_train.csv')\n",
        "\n",
        "# 범주형 변수 확인\n",
        "categorical_vars = df.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "# 범주형 변수를 원-핫 인코딩\n",
        "encoder = OneHotEncoder(sparse=False, drop='first')\n",
        "encoded_features = encoder.fit_transform(df[categorical_vars])\n",
        "\n",
        "# 인코딩된 데이터프레임 생성\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_vars))\n",
        "\n",
        "# 원래 데이터프레임에서 범주형 변수 제거하고 인코딩된 데이터프레임 추가\n",
        "df = df.drop(categorical_vars, axis=1)\n",
        "df = pd.concat([df, encoded_df], axis=1)\n",
        "\n",
        "# 데이터셋을 특징(features)과 목표(target)로 분리\n",
        "X = df.drop('SalePrice', axis=1)\n",
        "y = df['SalePrice']\n",
        "\n",
        "# 데이터셋을 훈련 및 테스트 세트로 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 특징을 스케일링\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 모델 생성\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_test_scaled, y_test))\n",
        "\n",
        "# 모델 평가\n",
        "test_loss = model.evaluate(X_test_scaled, y_test)\n",
        "print('테스트 손실:', test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# 데이터셋 로드\n",
        "df = pd.read_csv('house_train.csv')\n",
        "\n",
        "# 결측치 처리: 간단히 평균값으로 채우기\n",
        "df.fillna(df.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "# 범주형 변수 확인 및 원-핫 인코딩\n",
        "categorical_vars = df.select_dtypes(include=['object', 'category']).columns\n",
        "encoder = OneHotEncoder(sparse=False, drop='first')\n",
        "encoded_features = encoder.fit_transform(df[categorical_vars])\n",
        "\n",
        "# 인코딩된 데이터프레임 생성\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_vars))\n",
        "\n",
        "# 원래 데이터프레임에서 범주형 변수 제거하고 인코딩된 데이터프레임 추가\n",
        "df = df.drop(categorical_vars, axis=1)\n",
        "df = pd.concat([df, encoded_df], axis=1)\n",
        "\n",
        "# 데이터셋을 특징(features)과 목표(target)로 분리\n",
        "X = df.drop('SalePrice', axis=1)\n",
        "y = df['SalePrice']\n",
        "\n",
        "# 데이터셋을 훈련 및 테스트 세트로 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 특징을 스케일링\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 모델 생성\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model.add(Dropout(0.2))  # 과적합 방지를 위한 Dropout 층 추가\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test))\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_mae = model.evaluate(X_test_scaled, y_test)\n",
        "print('테스트 손실:', test_loss)\n",
        "print('테스트 MAE:', test_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Sk05rmj9D4G",
        "outputId": "67a77d91-379d-4fef-b3e6-57bd26c997d8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 37709586432.0000 - mae: 179802.0000 - val_loss: 39631822848.0000 - val_mae: 178778.7344\n",
            "Epoch 2/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 37856235520.0000 - mae: 180152.6094 - val_loss: 39341662208.0000 - val_mae: 177976.1719\n",
            "Epoch 3/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 36793798656.0000 - mae: 177090.8281 - val_loss: 37768298496.0000 - val_mae: 173560.6094\n",
            "Epoch 4/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 36912324608.0000 - mae: 174218.8906 - val_loss: 32901029888.0000 - val_mae: 159131.7500\n",
            "Epoch 5/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 29762664448.0000 - mae: 153395.9688 - val_loss: 23096520704.0000 - val_mae: 125288.4766\n",
            "Epoch 6/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19409803264.0000 - mae: 116339.4141 - val_loss: 11647977472.0000 - val_mae: 71583.6172\n",
            "Epoch 7/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9125010432.0000 - mae: 65290.2539 - val_loss: 6884522496.0000 - val_mae: 53549.7188\n",
            "Epoch 8/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5437845504.0000 - mae: 50236.8711 - val_loss: 6340409344.0000 - val_mae: 54785.3477\n",
            "Epoch 9/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4812798976.0000 - mae: 51075.0195 - val_loss: 6003388928.0000 - val_mae: 52143.7070\n",
            "Epoch 10/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5011868672.0000 - mae: 49258.8945 - val_loss: 5681518592.0000 - val_mae: 50825.7773\n",
            "Epoch 11/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5130018816.0000 - mae: 50286.9453 - val_loss: 5393762304.0000 - val_mae: 48948.9492\n",
            "Epoch 12/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3559791872.0000 - mae: 42728.8594 - val_loss: 5151564288.0000 - val_mae: 47474.7734\n",
            "Epoch 13/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4411777024.0000 - mae: 45577.2969 - val_loss: 4915580416.0000 - val_mae: 46062.9844\n",
            "Epoch 14/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3744184320.0000 - mae: 43843.5430 - val_loss: 4694575104.0000 - val_mae: 44722.9414\n",
            "Epoch 15/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3911090944.0000 - mae: 42885.2422 - val_loss: 4490188288.0000 - val_mae: 43075.3398\n",
            "Epoch 16/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3822777600.0000 - mae: 42102.1562 - val_loss: 4310652928.0000 - val_mae: 41047.8789\n",
            "Epoch 17/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3051097088.0000 - mae: 37621.1094 - val_loss: 4131718144.0000 - val_mae: 41198.0469\n",
            "Epoch 18/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3377718016.0000 - mae: 39131.3047 - val_loss: 3980308736.0000 - val_mae: 38669.7227\n",
            "Epoch 19/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2912558848.0000 - mae: 35385.6875 - val_loss: 3819676416.0000 - val_mae: 38457.3633\n",
            "Epoch 20/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3128160768.0000 - mae: 37370.2070 - val_loss: 3678141696.0000 - val_mae: 36933.6289\n",
            "Epoch 21/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2779417344.0000 - mae: 34883.6172 - val_loss: 3560440832.0000 - val_mae: 36048.0430\n",
            "Epoch 22/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2888588800.0000 - mae: 37149.7539 - val_loss: 3442897664.0000 - val_mae: 34602.1758\n",
            "Epoch 23/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2906633472.0000 - mae: 35455.7930 - val_loss: 3325775616.0000 - val_mae: 34241.7227\n",
            "Epoch 24/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2823779584.0000 - mae: 34654.7578 - val_loss: 3226125824.0000 - val_mae: 33441.0938\n",
            "Epoch 25/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2514818048.0000 - mae: 34472.4414 - val_loss: 3123426304.0000 - val_mae: 32810.4297\n",
            "Epoch 26/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2226735360.0000 - mae: 31992.4395 - val_loss: 3043303936.0000 - val_mae: 32228.6504\n",
            "Epoch 27/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2284808960.0000 - mae: 32614.0273 - val_loss: 2955721984.0000 - val_mae: 31798.6309\n",
            "Epoch 28/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2642760192.0000 - mae: 32713.5723 - val_loss: 2889954560.0000 - val_mae: 30670.4590\n",
            "Epoch 29/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2375597056.0000 - mae: 32580.4336 - val_loss: 2820180224.0000 - val_mae: 30518.1582\n",
            "Epoch 30/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1947012736.0000 - mae: 30712.1309 - val_loss: 2747213056.0000 - val_mae: 30658.1367\n",
            "Epoch 31/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2243919616.0000 - mae: 31578.1953 - val_loss: 2699188480.0000 - val_mae: 29417.7852\n",
            "Epoch 32/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2200113664.0000 - mae: 30650.2598 - val_loss: 2622659328.0000 - val_mae: 29845.4922\n",
            "Epoch 33/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2257813760.0000 - mae: 30996.5957 - val_loss: 2587296512.0000 - val_mae: 28767.3184\n",
            "Epoch 34/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1932643200.0000 - mae: 28850.6719 - val_loss: 2513082624.0000 - val_mae: 29350.4043\n",
            "Epoch 35/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2164450304.0000 - mae: 30460.7070 - val_loss: 2467180032.0000 - val_mae: 28717.9922\n",
            "Epoch 36/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2113294464.0000 - mae: 31105.4043 - val_loss: 2424007424.0000 - val_mae: 28244.8242\n",
            "Epoch 37/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2115368704.0000 - mae: 28912.7500 - val_loss: 2383934720.0000 - val_mae: 27919.8809\n",
            "Epoch 38/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2321035264.0000 - mae: 30315.0449 - val_loss: 2326276864.0000 - val_mae: 28059.8652\n",
            "Epoch 39/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1837946496.0000 - mae: 28096.3789 - val_loss: 2286007296.0000 - val_mae: 27708.4590\n",
            "Epoch 40/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1915185152.0000 - mae: 28532.4492 - val_loss: 2251904768.0000 - val_mae: 27339.5020\n",
            "Epoch 41/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1598703360.0000 - mae: 26822.0684 - val_loss: 2205660928.0000 - val_mae: 27319.9336\n",
            "Epoch 42/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1798143744.0000 - mae: 28261.0703 - val_loss: 2172633088.0000 - val_mae: 26962.5254\n",
            "Epoch 43/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1870046208.0000 - mae: 27833.9414 - val_loss: 2134354176.0000 - val_mae: 26845.1289\n",
            "Epoch 44/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1493600000.0000 - mae: 26610.5645 - val_loss: 2090918272.0000 - val_mae: 26873.6152\n",
            "Epoch 45/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1529596032.0000 - mae: 25894.5898 - val_loss: 2060111872.0000 - val_mae: 26620.8945\n",
            "Epoch 46/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1632796032.0000 - mae: 27350.2285 - val_loss: 2033130112.0000 - val_mae: 26292.5449\n",
            "Epoch 47/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1593967104.0000 - mae: 26541.7109 - val_loss: 2004921728.0000 - val_mae: 26093.1191\n",
            "Epoch 48/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1590220160.0000 - mae: 26150.8555 - val_loss: 1971795968.0000 - val_mae: 25939.3730\n",
            "Epoch 49/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1638876672.0000 - mae: 27104.9883 - val_loss: 1931979008.0000 - val_mae: 26061.9023\n",
            "Epoch 50/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2004185088.0000 - mae: 27615.1152 - val_loss: 1911633536.0000 - val_mae: 25672.6797\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1735618304.0000 - mae: 24314.6055\n",
            "테스트 손실: 1911633536.0\n",
            "테스트 MAE: 25672.6796875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# 데이터셋 로드\n",
        "df = pd.read_csv('/content/house_train.csv')\n",
        "\n",
        "# 결측치 처리: 간단히 평균값으로 채우기\n",
        "df.fillna(df.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "# 범주형 변수 확인 및 원-핫 인코딩\n",
        "categorical_vars = df.select_dtypes(include=['object', 'category']).columns\n",
        "encoder = OneHotEncoder(sparse=False, drop='first')\n",
        "encoded_features = encoder.fit_transform(df[categorical_vars])\n",
        "\n",
        "# 인코딩된 데이터프레임 생성\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_vars))\n",
        "\n",
        "# 원래 데이터프레임에서 범주형 변수 제거하고 인코딩된 데이터프레임 추가\n",
        "df = df.drop(categorical_vars, axis=1)\n",
        "df = pd.concat([df, encoded_df], axis=1)\n",
        "\n",
        "# 데이터셋을 특징(features)과 목표(target)로 분리\n",
        "X = df.drop('SalePrice', axis=1)\n",
        "y = df['SalePrice']\n",
        "\n",
        "# 데이터셋을 훈련 및 테스트 세트로 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 특징을 스케일링\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 모델 생성\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model.add(Dropout(0.2))  # 과적합 방지를 위한 Dropout 층 추가\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test))\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_mae = model.evaluate(X_test_scaled, y_test)\n",
        "print('\\n테스트 손실:', test_loss)\n",
        "print('테스트 MAE:', test_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_MSYiKP9WgP",
        "outputId": "6892987b-966b-4128-b94a-6e85b0745e70"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 37252669440.0000 - mae: 177637.7812 - val_loss: 39639470080.0000 - val_mae: 178799.7344\n",
            "Epoch 2/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 38548029440.0000 - mae: 180296.2344 - val_loss: 39434702848.0000 - val_mae: 178233.9062\n",
            "Epoch 3/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 38747230208.0000 - mae: 180640.1094 - val_loss: 38228467712.0000 - val_mae: 174863.6562\n",
            "Epoch 4/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 37006262272.0000 - mae: 175654.6250 - val_loss: 34206842880.0000 - val_mae: 163129.9375\n",
            "Epoch 5/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29636456448.0000 - mae: 155610.5000 - val_loss: 25532479488.0000 - val_mae: 134432.2812\n",
            "Epoch 6/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22150928384.0000 - mae: 125797.3203 - val_loss: 13785931776.0000 - val_mae: 83330.0469\n",
            "Epoch 7/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10855262208.0000 - mae: 76003.5156 - val_loss: 7166464512.0000 - val_mae: 53186.9766\n",
            "Epoch 8/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5463963136.0000 - mae: 49165.4180 - val_loss: 6392459776.0000 - val_mae: 55247.3945\n",
            "Epoch 9/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5664896000.0000 - mae: 52654.7695 - val_loss: 6046196736.0000 - val_mae: 53023.9180\n",
            "Epoch 10/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4782115328.0000 - mae: 49354.5742 - val_loss: 5726547968.0000 - val_mae: 51307.0547\n",
            "Epoch 11/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5341184512.0000 - mae: 48336.3164 - val_loss: 5442326528.0000 - val_mae: 49670.4570\n",
            "Epoch 12/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4619199488.0000 - mae: 46095.3750 - val_loss: 5189797888.0000 - val_mae: 47793.8477\n",
            "Epoch 13/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4511367168.0000 - mae: 45144.0156 - val_loss: 4952703488.0000 - val_mae: 46312.1445\n",
            "Epoch 14/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3549068544.0000 - mae: 41040.3516 - val_loss: 4728784896.0000 - val_mae: 45486.3359\n",
            "Epoch 15/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3994851840.0000 - mae: 43593.7227 - val_loss: 4532979712.0000 - val_mae: 42784.2734\n",
            "Epoch 16/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4002619136.0000 - mae: 42403.8516 - val_loss: 4332905472.0000 - val_mae: 41637.4883\n",
            "Epoch 17/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3323575040.0000 - mae: 38691.1445 - val_loss: 4153319424.0000 - val_mae: 40761.4375\n",
            "Epoch 18/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3090646272.0000 - mae: 39586.6172 - val_loss: 3981673728.0000 - val_mae: 39230.2930\n",
            "Epoch 19/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3338531072.0000 - mae: 37179.6719 - val_loss: 3827865856.0000 - val_mae: 38556.1523\n",
            "Epoch 20/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2977610496.0000 - mae: 37385.2148 - val_loss: 3683062528.0000 - val_mae: 37559.4688\n",
            "Epoch 21/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3757963264.0000 - mae: 39480.1797 - val_loss: 3570281728.0000 - val_mae: 35048.8320\n",
            "Epoch 22/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2783632128.0000 - mae: 33895.7969 - val_loss: 3433302528.0000 - val_mae: 34804.7617\n",
            "Epoch 23/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2605867264.0000 - mae: 33323.1367 - val_loss: 3316541184.0000 - val_mae: 34546.9414\n",
            "Epoch 24/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2651167488.0000 - mae: 33221.1484 - val_loss: 3214044928.0000 - val_mae: 33394.0820\n",
            "Epoch 25/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2292177920.0000 - mae: 32196.1582 - val_loss: 3119385600.0000 - val_mae: 32957.9219\n",
            "Epoch 26/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2058452864.0000 - mae: 30672.5488 - val_loss: 3028107008.0000 - val_mae: 33191.9531\n",
            "Epoch 27/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2468467968.0000 - mae: 33195.3125 - val_loss: 2954668800.0000 - val_mae: 31000.5781\n",
            "Epoch 28/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1886059648.0000 - mae: 29205.9121 - val_loss: 2864109312.0000 - val_mae: 31175.7773\n",
            "Epoch 29/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2248656384.0000 - mae: 31440.3105 - val_loss: 2799139584.0000 - val_mae: 30083.2812\n",
            "Epoch 30/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1868012288.0000 - mae: 29355.2305 - val_loss: 2723909888.0000 - val_mae: 30621.0234\n",
            "Epoch 31/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2258809088.0000 - mae: 31847.5898 - val_loss: 2665460736.0000 - val_mae: 29454.7461\n",
            "Epoch 32/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2037964160.0000 - mae: 30908.6543 - val_loss: 2601144064.0000 - val_mae: 29286.9922\n",
            "Epoch 33/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2508242688.0000 - mae: 31243.0508 - val_loss: 2541521664.0000 - val_mae: 29143.2090\n",
            "Epoch 34/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2353211136.0000 - mae: 30037.0293 - val_loss: 2498580480.0000 - val_mae: 28512.0898\n",
            "Epoch 35/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2337998592.0000 - mae: 30947.3105 - val_loss: 2443110400.0000 - val_mae: 28489.9883\n",
            "Epoch 36/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2373269248.0000 - mae: 30124.1680 - val_loss: 2390783232.0000 - val_mae: 28354.2285\n",
            "Epoch 37/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1913714048.0000 - mae: 29480.9883 - val_loss: 2346431744.0000 - val_mae: 28007.5371\n",
            "Epoch 38/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2390275584.0000 - mae: 29999.0898 - val_loss: 2296650752.0000 - val_mae: 27932.3555\n",
            "Epoch 39/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1552017152.0000 - mae: 26810.3789 - val_loss: 2268495360.0000 - val_mae: 27341.8438\n",
            "Epoch 40/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1904820352.0000 - mae: 27694.7930 - val_loss: 2223151360.0000 - val_mae: 27185.9512\n",
            "Epoch 41/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1912306304.0000 - mae: 28773.6562 - val_loss: 2194328064.0000 - val_mae: 26827.7461\n",
            "Epoch 42/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1848699392.0000 - mae: 28005.1055 - val_loss: 2137289216.0000 - val_mae: 27047.6348\n",
            "Epoch 43/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1923636864.0000 - mae: 27713.8281 - val_loss: 2116727936.0000 - val_mae: 26528.1309\n",
            "Epoch 44/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1941102976.0000 - mae: 27817.3438 - val_loss: 2061619328.0000 - val_mae: 26734.3223\n",
            "Epoch 45/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1764353408.0000 - mae: 27114.0195 - val_loss: 2042097280.0000 - val_mae: 26235.5762\n",
            "Epoch 46/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1789963776.0000 - mae: 28377.8516 - val_loss: 2012487808.0000 - val_mae: 26064.8672\n",
            "Epoch 47/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1838865664.0000 - mae: 26475.1621 - val_loss: 2003735424.0000 - val_mae: 25733.7539\n",
            "Epoch 48/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1512056192.0000 - mae: 26220.8750 - val_loss: 1950642432.0000 - val_mae: 25904.3027\n",
            "Epoch 49/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1451449984.0000 - mae: 25771.2539 - val_loss: 1932429312.0000 - val_mae: 25604.5664\n",
            "Epoch 50/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1356181248.0000 - mae: 25482.3867 - val_loss: 1892212352.0000 - val_mae: 25643.3672\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1713942016.0000 - mae: 24228.2676\n",
            "\n",
            "테스트 손실: 1892212352.0\n",
            "테스트 MAE: 25643.3671875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NeMVa3YECcBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "868b8d1a-5bb9-4ed9-f91b-312edc242fed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "결측치:\n",
            " LotFrontage      259\n",
            "Alley           1369\n",
            "MasVnrType       872\n",
            "MasVnrArea         8\n",
            "BsmtQual          37\n",
            "BsmtCond          37\n",
            "BsmtExposure      38\n",
            "BsmtFinType1      37\n",
            "BsmtFinType2      38\n",
            "Electrical         1\n",
            "FireplaceQu      690\n",
            "GarageType        81\n",
            "GarageYrBlt       81\n",
            "GarageFinish      81\n",
            "GarageQual        81\n",
            "GarageCond        81\n",
            "PoolQC          1453\n",
            "Fence           1179\n",
            "MiscFeature     1406\n",
            "dtype: int64\n",
            "범주형 변수:\n",
            " Index(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
            "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
            "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
            "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
            "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
            "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
            "       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
            "       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
            "       'SaleType', 'SaleCondition'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# 결측치 확인\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"결측치:\\n\", missing_values[missing_values > 0])\n",
        "\n",
        "# 범주형 변수 확인\n",
        "categorical_vars = df.select_dtypes(include=['object', 'category']).columns\n",
        "print(\"범주형 변수:\\n\", categorical_vars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaEOzhogCb_N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQqdaOaECb9G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Sye-_w7Cb7G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISftcHdmCb49"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb9QPXrvCb2-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWJb45O4Cb1O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVesSPBFCby2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LsznRUmCbw2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wihCbP_rCbs2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gh1H1b2ECbq1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EL9m9nr6Cbou"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1WKoYBUZjzCTtB-Z7rqKuWnURnMu3MoPS",
      "authorship_tag": "ABX9TyPg8lHVQ6cWgRHjZHfnKKNf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}