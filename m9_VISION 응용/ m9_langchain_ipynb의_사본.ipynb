{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2CBjCESlEo77CR6LM59x0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/windyday0622/windyday/blob/main/m9_VISION%20%EC%9D%91%EC%9A%A9/%20m9_langchain_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain\n",
        "- 자연어 처리(NLP)와 생성형 AI 응용 프로그램을 개발하기 위한 프레임워크입니다. 주로 대형 언어 모델(LLMs)과 같은 최신 NLP 기술을 기반으로 하여 다양한 작업을 자동화하거나 개선할 수 있는 도구와 서비스를 제공합니다.\n",
        "- 이 프레임워크는 특히 언어 모델의 기능을 확장하고 이를 보다 쉽게 사용할 수 있도록 설계되었습니다.\n",
        "- LangChain의 핵심 목표는 언어 모델을 활용하여 여러 복잡한 작업을 수행할 수 있도록 돕는 것이며, 특히 긴 텍스트, 문서 체인 또는 여러 단계의 워크플로를 필요로 하는 복잡한 응용 프로그램에 유용합니다.\n",
        "\n",
        "### LangChain의 구성 요소:\n",
        "- Language Models: 언어 모델 자체를 사용하여 텍스트 생성, 요약, 번역 등의 작업을 수행합니다.\n",
        "- Chains: 여러 모델 호출을 연결하여 복잡한 작업을 수행하는 논리적 흐름을 정의할 수 있습니다. 예를 들어, 텍스트를 요약한 후 요약된 텍스트에 대한 질의응답을 수행하는 체인을 만들 수 있습니다.\n",
        "- Agents: 주어진 작업에 따라 다양한 툴을 선택하고 사용할 수 있는 지능형 에이전트입니다. 예를 들어, 정보 검색, API 호출 등을 수행하는 역할을 합니다.\n",
        "- Memory: 이전의 상호작용 또는 맥락을 기억하는 기능입니다. 이를 통해 대화형 AI나 컨텍스트를 유지해야 하는 애플리케이션을 구현할 수 있습니다.\n",
        "\n",
        "### 활용 사례:\n",
        "- 대화형 에이전트: 사용자와의 대화에서 맥락을 유지하며 대답할 수 있는 챗봇 개발.\n",
        "문서 처리: 긴 문서나 여러 문서의 내용을 요약하거나 분석하는 애플리케이션.\n",
        "- 지식 탐색: 사용자가 특정 주제에 대해 질문하면, 관련된 정보를 검색하고 이를 바탕으로 대답을 제공하는 시스템.\n",
        "\n",
        "### 통합:\n",
        "- LangChain은 다양한 데이터 소스, API 및 언어 모델과 통합될 수 있으며, 이를 통해 다양한 도메인에서 사용될 수 있습니다. 예를 들어, SQL 데이터베이스에 쿼리를 보내고 결과를 요약하거나, 웹에서 정보를 수집한 후 이를 기반으로 질문에 답하는 작업을 수행할 수 있습니다.\n",
        "\n",
        "이 프레임워크는 특히 연구자, 데이터 사이언티스트, 개발자들이 생성형 AI를 활용하여 복잡한 텍스트 기반 응용 프로그램을 구축하는 데 큰 도움이 됩니다. LangChain은 이러한 작업을 더 쉽게, 더 직관적으로 구현할 수 있게 도와줍니다."
      ],
      "metadata": {
        "id": "xj5i4zKNqINC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- langchain-openai: LangChain과 OpenAI를 연결하는 패키지.\n",
        "- faiss-cpu: 벡터 검색을 위한 FAISS 라이브러리의 CPU 버전.\n",
        "- langchain_community: LangChain의 커뮤니티에서 개발된 추가 도구.\n",
        "- tiktoken: OpenAI 모델에서 사용하는 토큰화 도구."
      ],
      "metadata": {
        "id": "HCGV_huFu-bx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yrqwPYaqElr",
        "outputId": "5c4b83a7-a66c-47ed-85e5-8f2a17625d55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/362.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.4/362.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.8/997.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m391.5/391.5 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q openai\n",
        "!pip install langchain langchain-openai -q\n",
        "!pip install faiss-cpu -q\n",
        "!pip install langchain_community -q\n",
        "!pip install tiktoken -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "MODEL = 'gpt-4o-mini-2024-07-18'\n",
        "client = openai.OpenAI(api_key=\"\")"
      ],
      "metadata": {
        "id": "i3H2j6NQqJvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content = \"\"\"\n",
        "Document 1:\n",
        "Polar bears are directly impacted by climate change due to their dependence on sea ice for hunting seals. As global temperatures rise, sea ice is melting earlier and forming later each year, reducing the time polar bears have to hunt. This has led to decreased body condition, lower cub survival rates, and in some cases, increased mortality.\n",
        "\n",
        "Document 2:\n",
        "The loss of sea ice habitat is one of the most significant threats to polar bear populations. As the ice retreats, polar bears are forced to travel greater distances to find food, leading to increased energy expenditure. This can result in malnutrition and a decline in reproductive success, further endangering the species.\n",
        "\n",
        "Document 3:\n",
        "Climate change is not only affecting polar bears' hunting grounds but also their denning areas. Warmer temperatures and unstable snow conditions are making it more difficult for pregnant females to find suitable denning sites, which is crucial for the birth and survival of their cubs. This adds an additional layer of risk to polar bear populations already struggling due to loss of sea ice.\n",
        "\n",
        "Document 4:\n",
        "As their traditional food sources become less accessible, some polar bears have been observed scavenging on human waste or preying on seabirds and their eggs. While this behavior may provide some short-term relief, it does not replace the high-fat diet they obtain from seals, which is essential for their long-term survival in the harsh Arctic environment.\n",
        "\n",
        "Document 5:\n",
        "Recent studies suggest that if current trends in greenhouse gas emissions continue, polar bears could face extinction within this century. Conservation efforts are focusing on reducing global emissions and protecting critical polar bear habitats, but these efforts may not be sufficient if the climate continues to warm at the current rate.\n",
        "\"\"\"\n",
        "\n",
        "# Write the content to a file\n",
        "with open('document.txt', 'w') as file:\n",
        "    file.write(content)"
      ],
      "metadata": {
        "id": "lyota7rIqJtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez1veHazqJrR",
        "outputId": "850292a9-9a80-4de7-9515-1f976f1a07f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "document.txt  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "o9TfiYGWqJpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- OpenAIEmbeddings: 문서를 벡터로 임베딩하는 클래스입니다. 각 문서를 숫자 벡터로 변환하여 유사성 검색을 할 수 있게 만듭니다.\n",
        "- ChatOpenAI: OpenAI의 GPT 모델을 사용하는 클래스입니다. model을 지정하여 특정 GPT 모델을 사용할 수 있으며, fine-tuned된 모델도 지원합니다.\n",
        "- FAISS(Facebook AI Similarity Search): 벡터를 빠르게 검색하기 위한 라이브러리입니다. Facebook에서 개발한 AI 유사성 검색 라이브러리로, 임베딩된 문서들 중에서 가장 관련성이 높은 문서를 빠르게 검색할 수 있습니다.\n",
        "- TextLoader: 문서를 텍스트 형식으로 불러오는 클래스입니다. 이 클래스는 주어진 파일에서 텍스트 데이터를 로드할 때 사용됩니다.\n",
        "- RetrievalQA: 검색된 문서와 GPT 모델을 결합하여 질의응답 작업을 수행하는 체인입니다."
      ],
      "metadata": {
        "id": "UfG1Jj06Lc1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "# 문서 로드\n",
        "loader = TextLoader('document.txt')\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "qTLxRaxCqJnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 코드는 문서를 로드하는 부분입니다.\n",
        "\n",
        "- **TextLoader**를 사용하여 documents.txt 파일을 불러옵니다. 이 파일은 시스템에서 검색할 수 있는 문서들이 포함된 파일입니다.\n",
        "- **loader.load()**를 호출하여 문서를 읽어들이고, 이를 documents라는 변수에 저장합니다. 이 변수는 나중에 벡터화(임베딩)할 때 사용됩니다."
      ],
      "metadata": {
        "id": "1UkuCHK9Nk-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()\n",
        "vector_store = FAISS.from_documents(documents, embeddings)"
      ],
      "metadata": {
        "id": "8NB0NpthqJlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 부분은 문서를 벡터로 변환하고 이를 인덱싱하는 단계입니다.\n",
        "\n",
        "- OpenAIEmbeddings: 문서를 숫자 벡터로 변환하는데 사용됩니다. 임베딩은 텍스트의 의미를 벡터 공간에서 표현하는 방법으로, 유사성 검색에 중요한 역할을 합니다.\n",
        "- FAISS.from_documents: documents 변수를 임베딩한 후, FAISS 인덱스를 생성합니다. 이 인덱스는 문서를 벡터로 변환한 후 빠르게 유사성을 계산하고 관련 문서를 검색하는 데 사용됩니다."
      ],
      "metadata": {
        "id": "NN6vMurKOiET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\", temperature=0.3)"
      ],
      "metadata": {
        "id": "aI3cmR3WqJip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 부분은 GPT 모델을 설정하는 부분입니다.\n",
        "\n",
        "- ChatOpenAI: OpenAI의 GPT 모델을 사용합니다. 여기서 model 파라미터로 Fine-tuned된 GPT 모델을 지정하고 있습니다. \"gpt-4o-mini-2024-07-18\"은 Fine-tuning된 GPT 모델의 ID입니다.\n",
        "- temperature: 텍스트 생성을 제어하는 파라미터로, 값이 낮을수록 더 결정적인(deterministic) 결과를 생성하고, 값이 높을수록 생성되는 텍스트의 창의성(랜덤성)이 높아집니다."
      ],
      "metadata": {
        "id": "Off0RQVfPCcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문서 검색 개수 조정(최상위 5개의 유사한 벡터를 반환)\n",
        "# 사용자가 입력한 쿼리와 가장 유사한 5개의 결과를 검색하여 반환하겠다는 의미\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\":5})"
      ],
      "metadata": {
        "id": "zGf7tkEmqJeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 부분에서는 검색할 문서의 개수를 설정합니다.\n",
        "\n",
        "- retriever: vector_store에서 as_retriever 메서드를 사용하여 문서 검색을 위한 리트리버(retriever)를 생성합니다.\n",
        "- k 값: search_kwargs에서 k를 5로 설정하여, 사용자가 질문을 할 때 최대 5개의 문서가 검색되도록 설정합니다. 즉, 질문과 관련된 상위 5개의 문서를 검색하여 답변에 사용할 수 있도록 합니다."
      ],
      "metadata": {
        "id": "GnaEqmxpPwZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG 구현\n",
        "# RetriverIQA 체인을 사용해 검색된 문서를 기반으로 LLM을 통해 답변을 생성\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type = \"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "Ziea124oqJco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 부분은 Retrieval-Augmented Generation (RAG) 체인을 구현하는 부분입니다.\n",
        "\n",
        "- RetrievalQA: RetrievalQA 체인은 검색된 문서를 GPT 모델과 결합하여 질문에 대한 답변을 생성합니다.\n",
        "- from_chain_type: 여기서는 \"stuff\" 체인 유형을 사용합니다. 이는 검색된 문서들을 모두 결합하여 하나의 텍스트로 처리하는 방식입니다.\n",
        "  다른 체인 방식으로는 map-reduce나 refine 등의 방법이 있습니다.\n",
        "  - Map-reduce: 문서를 나눠서 처리하고, 나중에 결합하는 방식.\n",
        "  - Refine: 문서를 한 번에 하나씩 처리하고, 그 결과를 점진적으로 개선하는 방식.\n",
        "- retriever: 이 retriever는 벡터 스토어(예: FAISS)에서 관련 문서를 검색한 후, 해당 문서들을 LLM에게 제공하여 답변을 생성하도록 돕습니다.\n",
        "- return_source_documents=True: 검색된 문서를 응답에 포함하여 반환할지 여부를 지정합니다. True로 설정하면, 검색된 문서들을 답변과 함께 반환합니다. 이렇게 하면 사용자가 생성된 답변 외에도 검색된 문서들을 검토할 수 있습니다."
      ],
      "metadata": {
        "id": "EtfDjjugTY-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 질문에 대한 답변 생성\n",
        "query = \"What is the impact of climate change on polar bears?\"\n",
        "result = qa_chain.invoke({\"query\":query})\n",
        "\n",
        "print(result[\"result\"])"
      ],
      "metadata": {
        "id": "FBZtO7_aqJaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df6b23b-4fce-4c1b-8317-199c99aaf039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Climate change significantly impacts polar bears primarily through the loss of sea ice, which is crucial for their hunting and survival. As global temperatures rise, sea ice is melting earlier and forming later each year, reducing the time polar bears have to hunt seals. This leads to decreased body condition, lower cub survival rates, and increased mortality.\n",
            "\n",
            "Additionally, the retreating ice forces polar bears to travel greater distances to find food, resulting in increased energy expenditure and potential malnutrition. Warmer temperatures also affect their denning areas, making it more challenging for pregnant females to find suitable sites for giving birth, which is vital for cub survival.\n",
            "\n",
            "As traditional food sources become less accessible, some polar bears have started scavenging on human waste or preying on seabirds, but these alternatives do not provide the necessary nutrition for their long-term survival. If current trends in greenhouse gas emissions continue, polar bears could face extinction within this century.\n"
          ]
        }
      ]
    }
  ]
}