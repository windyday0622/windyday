{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMmmMTqmshBBgTTe7FVTDT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/windyday0622/windyday/blob/main/m9_VISION%20%EC%9D%91%EC%9A%A9/%20gradio_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.gradio.app/guides"
      ],
      "metadata": {
        "id": "NkhO-IXcqcgF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GradioëŠ” Python ê¸°ë°˜ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë˜ëŠ” ì¼ë°˜ì ì¸ í•¨ìˆ˜ì™€ ì‚¬ìš©ì ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ ìœ„í•œ ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ ê°„ë‹¨í•˜ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤. Gradioë¥¼ ì‚¬ìš©í•˜ë©´ ëª‡ ì¤„ì˜ ì½”ë“œë¡œ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ í†µí•´ ëª¨ë¸ì´ë‚˜ í•¨ìˆ˜ë¥¼ ì‚¬ìš©ìì—ê²Œ ì‰½ê²Œ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "**Gradioì˜ ê¸°ë³¸ ê°œë…**\n",
        "\n",
        "- ì›¹ ì¸í„°í˜ì´ìŠ¤: GradioëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë˜ëŠ” ì¼ë°˜ì ì¸ íŒŒì´ì¬ í•¨ìˆ˜ë¥¼ ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ UIë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì‚¬ìš©ìëŠ” ëª¨ë¸ì„ ì§ì ‘ ì…ë ¥ê°’ì„ ì£¼ê±°ë‚˜ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "- ì‚¬ìš©ì ìƒí˜¸ì‘ìš©: GradioëŠ” í…ìŠ¤íŠ¸ ì…ë ¥, íŒŒì¼ ì—…ë¡œë“œ, ë“œë¡­ë‹¤ìš´ ë©”ë‰´ ë“± ë‹¤ì–‘í•œ ìœ„ì ¯ì„ ì œê³µí•˜ì—¬ ì‚¬ìš©ìê°€ ì‰½ê²Œ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "- ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘: ë³µì¡í•œ ì›¹ ì„œë²„ ì„¤ì • ì—†ì´ë„ ê°„ë‹¨í•˜ê²Œ ëª¨ë¸ì„ ì›¹ì—ì„œ í…ŒìŠ¤íŠ¸í•˜ê³  ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "**Gradioì˜ í•µì‹¬ ê¸°ëŠ¥**\n",
        "- ì¸í„°í˜ì´ìŠ¤ êµ¬ì„± ìš”ì†Œ:\n",
        "GradioëŠ” ë‹¤ì–‘í•œ ì…ë ¥ ë° ì¶œë ¥ ìœ„ì ¯ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ ê¸°ë°˜ ì¸í„°í˜ì´ìŠ¤ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "  - ì…ë ¥ ìœ„ì ¯: Textbox, Dropdown, Slider, Checkbox, FileUpload ë“±\n",
        "  - ì¶œë ¥ ìœ„ì ¯: Textbox, Label, Image, Audio, Video ë“±\n",
        "\n",
        "GradioëŠ” Python ê¸°ë°˜ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë˜ëŠ” ì¼ë°˜ì ì¸ í•¨ìˆ˜ì™€ ì‚¬ìš©ì ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ ìœ„í•œ ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ ê°„ë‹¨í•˜ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤. Gradioë¥¼ ì‚¬ìš©í•˜ë©´ ëª‡ ì¤„ì˜ ì½”ë“œë¡œ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ í†µí•´ ëª¨ë¸ì´ë‚˜ í•¨ìˆ˜ë¥¼ ì‚¬ìš©ìì—ê²Œ ì‰½ê²Œ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "**Gradioì˜ ê¸°ë³¸ ê°œë…**\n",
        "\n",
        "- ì›¹ ì¸í„°í˜ì´ìŠ¤: GradioëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë˜ëŠ” ì¼ë°˜ì ì¸ íŒŒì´ì¬ í•¨ìˆ˜ë¥¼ ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ UIë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì‚¬ìš©ìëŠ” ëª¨ë¸ì„ ì§ì ‘ ì…ë ¥ê°’ì„ ì£¼ê±°ë‚˜ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "- ì‚¬ìš©ì ìƒí˜¸ì‘ìš©: GradioëŠ” í…ìŠ¤íŠ¸ ì…ë ¥, íŒŒì¼ ì—…ë¡œë“œ, ë“œë¡­ë‹¤ìš´ ë©”ë‰´ ë“± ë‹¤ì–‘í•œ ìœ„ì ¯ì„ ì œê³µí•˜ì—¬ ì‚¬ìš©ìê°€ ì‰½ê²Œ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "- ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘: ë³µì¡í•œ ì›¹ ì„œë²„ ì„¤ì • ì—†ì´ë„ ê°„ë‹¨í•˜ê²Œ ëª¨ë¸ì„ ì›¹ì—ì„œ í…ŒìŠ¤íŠ¸í•˜ê³  ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "**Gradioì˜ í•µì‹¬ ê¸°ëŠ¥**\n",
        "- ì¸í„°í˜ì´ìŠ¤ êµ¬ì„± ìš”ì†Œ:\n",
        "GradioëŠ” ë‹¤ì–‘í•œ ì…ë ¥ ë° ì¶œë ¥ ìœ„ì ¯ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ ê¸°ë°˜ ì¸í„°í˜ì´ìŠ¤ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "  - ì…ë ¥ ìœ„ì ¯: Textbox, Dropdown, Slider, Checkbox, FileUpload ë“±\n",
        "  - ì¶œë ¥ ìœ„ì ¯: Textbox, Label, Image, Audio, Video ë“±"
      ],
      "metadata": {
        "id": "h4RtWV0driHl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "craiqrJdkNGk",
        "outputId": "78a803e9-8931-4b30-b13c-5bad8e61dc4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def greet(name):\n",
        "    return \"Hello, \" + name + \"!\"\n",
        "\n",
        "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "pTwbEBwwqgjE",
        "outputId": "a45d61b8-85b1-4834-b452-ea1678addaba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://c4117c03cf5d745a2f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c4117c03cf5d745a2f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def greet(name):\n",
        "    return \"Hello, \" + name + \"!\"\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=greet,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Name here...\"),\n",
        "    outputs=gr.Textbox(),\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "pkhNtdPkwCik",
        "outputId": "0743361d-fd32-4ba0-efc6-92dfd98b51a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://4cd620338b273f2e99.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4cd620338b273f2e99.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def greet(name, is_morning, temperature):\n",
        "    salutation = \"Good morning\" if is_morning else \"Good evening\"\n",
        "    greeting = f\"{salutation}, {name}. It is {temperature} degrees today\"\n",
        "    celsius = (temperature - 32) * 5/9\n",
        "    return greeting, round(celsius, 2)\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=greet,\n",
        "    inputs=[\"text\", \"checkbox\", gr.Slider(0, 100)],\n",
        "    outputs=[\"text\", \"number\"]\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "qd-TbydBwCfE",
        "outputId": "98f8fcd9-7be0-4b23-ca2f-a56ef890faf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://ee65c23610db5a2cb4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ee65c23610db5a2cb4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gradio as gr\n",
        "from skimage.transform import resize\n",
        "\n",
        "def sepia(input_img):\n",
        "    input_img = resize(input_img, (200, 200))\n",
        "    sepia_filter = np.array([[0.393, 0.769, 0.189],\n",
        "                             [0.349, 0.686, 0.168],\n",
        "                             [0.272, 0.534, 0.131]])\n",
        "\n",
        "    sepia_img = input_img.dot(sepia_filter.T)\n",
        "    sepia_img /= sepia_img.max()\n",
        "    return sepia_img\n",
        "\n",
        "demo = gr.Interface(fn=sepia, inputs=gr.Image(), outputs=gr.Image())\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "LZRX_XlhwCc8",
        "outputId": "4a1f0aa5-a89a-4f64-aaed-ad89703c9eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://0b1943afc9057ef1b1.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0b1943afc9057ef1b1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def bmi(name, height, weight, feeling):\n",
        "    bmi_val = round(weight / ((height/100) **2),2)\n",
        "    result_emoticon = \"ğŸ˜Š\" if bmi_val < 30 else \"ğŸ˜”\"\n",
        "    output_Str = 'Hello ' + name + '... \\n your BMI is ... ' + str(bmi_val)\n",
        "    txt = \"Happy\" if feeling else \"Sad\"\n",
        "    return (output_Str, result_emoticon, txt)\n",
        "\n",
        "bmi(\"Hyunjin\", 155, 50, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNEKEB57wCak",
        "outputId": "d101278a-18d3-4524-e96b-dfd715ba036b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Hello Hyunjin... \\n your BMI is ... 20.81', 'ğŸ˜Š', 'Happy')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "flag = pd.read_csv(\"/content/flagged/log.csv\")\n",
        "flag"
      ],
      "metadata": {
        "id": "DqoaXBYT6du1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=bmi,\n",
        "    inputs=[\"text\", gr.Slider(1, 200, label=\"Height in cm\"), gr.Slider(1, 100, label=\"Weight in kg\"),\n",
        "            gr.Checkbox(label=\"You are feeling today\")],\n",
        "    outputs=[\"text\", \"text\", \"text\"],\n",
        "    examples=[\n",
        "        [\"Hyunjin\", 155, 50, True],\n",
        "        [\"John\", 180, 80, False],\n",
        "        [\"Jane\", 160, 70, True]],\n",
        "        live = True,\n",
        "        description = \"Flag if you find an erroneous output\"\n",
        ")\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "VeRwZ9AqwCW_",
        "outputId": "c8fab396-d4f4-4eb8-fa84-242d2a87cbb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://366fc39d1520492956.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://366fc39d1520492956.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Blocks\n",
        "- Gradioì˜ ì €ìˆ˜ì¤€ APIë¡œ ì¸í„°í˜ì´ìŠ¤ë³´ë‹¤ ë” ë§ì€ ì‚¬ìš©ì ì§€ì • ì›¹ ì‘ìš© í”„ë¡œê·¸ë¨ ë° ë°ëª¨ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤(ì•„ì§ ì™„ì „íˆ Pythonìœ¼ë¡œ).\n",
        "- ì¸í„°í˜ì´ìŠ¤ í´ë˜ìŠ¤ì— ë¹„í•´ BlocksëŠ” ë‹¤ìŒì— ëŒ€í•´ ë” ë§ì€ ìœ ì—°ì„±ê³¼ ì œì–´ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "- BlocksëŠ” ë˜í•œ íƒ­ê³¼ ê°™ì€ ê´€ë ¨ ë°ëª¨ë¥¼ í•¨ê»˜ ê·¸ë£¹í™”í•˜ëŠ” ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "- Blocks ê°ì²´ë¥¼ ìƒì„±í•œ ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•˜ê³ (\"with\" ë¬¸ ì‚¬ìš©) Blocks ì»¨í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ë ˆì´ì•„ì›ƒ, êµ¬ì„± ìš”ì†Œ ë˜ëŠ” ì´ë²¤íŠ¸ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ launch() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ ë°ëª¨ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "7VIBeERW-K0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(name):\n",
        "    return \"Hello, \" + name + \"!\"\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    text_input = gr.Textbox(label=\"Enter your text\")\n",
        "    output = gr.Textbox(label=\"Output\")\n",
        "    btn = gr.Button(\"Submit\")\n",
        "\n",
        "    btn.click(fn=greet, inputs=text_input, outputs=output)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "qmXYjbFcwCU8",
        "outputId": "e7fd9bc1-87de-4114-f60c-1c0fc97dc87c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://64c15d1a68918cb0ab.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://64c15d1a68918cb0ab.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ì‹¤ìŠµ\n",
        "ì½”ë”©íŠœí„°ëŠ” ê³ ë“±í•™ìƒ ì •ë³´ê³¼ëª©ì—ì„œ ì•Œê³ ë¦¬ì¦˜ê³¼ í”„ë¡œê·¸ë˜ë°ì„ í•™ìƒë“¤ì´ ì‹¤ìŠµí•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ëŠ” íŠœí„°ë´‡"
      ],
      "metadata": {
        "id": "Rg2IJWFqAW_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ê¸°ë³¸ ëª¨ë¸ - Few-shot"
      ],
      "metadata": {
        "id": "PG2d5KaKAwE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a3k0_0KBJit",
        "outputId": "6236353b-158a-496c-d806-eb0adb3dd2b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/362.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m358.4/362.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m362.9/362.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/318.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28.0 -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2HPUuGOBYVt",
        "outputId": "c79a168b-5630-4d49-dff9-60149634c3ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"\"\n",
        "\n",
        "system_msg = \"\"\"ì½”ë”©íŠœí„°ëŠ” ê³ ë“±í•™ìƒ ì •ë³´ê³¼ëª©ì—ì„œ ì•Œê³ ë¦¬ì¦˜ê³¼ í”„ë¡œê·¸ë˜ë°ì„ í•™ìƒë“¤ì´ ì‹¤ìŠµí•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ëŠ” íŠœí„°ë´‡ì…ë‹ˆë‹¤.\n",
        "                - íŠœí„°ëŠ” \"ë°˜ê°€ì™€ìš”~ \"ë¼ê³  ì¸ì‚¬ë§ë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
        "                - í•™ìƒì´ ì„ íƒí•œ ì„¹ì…˜ìœ¼ë¡œ í•™ìŠµì„ ì‹œì‘í•˜ê³  ë¨¼ì € ê°„ë‹¨í•˜ê²Œ ì„¹ì…˜ í•™ìŠµë‚´ìš© ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "                - ê° ì„¹ì…˜ë³„ í•™ìŠµ í•­ëª©ì— ëŒ€í•´ì„œ í•˜ë‚˜ì”© ê°œë…ì„ ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•˜ê³  ì—°ìŠµë¬¸ì œë¥¼ ì¶”ê°€ë¡œ ì œê³µí•´ì„œ ê° ê°œë…ì„ ì´í•´í•˜ì—¬ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì—°ìŠµí•©ë‹ˆë‹¤.\n",
        "                - í•™ìƒì˜ ë‹µë³€ì— ëŒ€í•´ì„œ \"ì˜í–ˆì–´ìš”!\",\"ì¡°ê¸ˆ ë” ìƒê°í•´ë´ìš”~\" ì™€ ê°™ì€ ê¸ì •ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "                - ëŒ€í™”ëŠ” ê°„ê²°í•˜ê²Œ ìœ ì§€í•˜ë©°, ìµœëŒ€ 100ì ì´ë‚´ë¡œ ì§„í–‰í•©ë‹ˆë‹¤. ë‹¨ ì½”ë“œëŠ” 300ì ì´ë‚´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.\n",
        "                - íŠœí„°ëŠ” í•™ìƒë“¤ì´ ìê¸°ì£¼ë„ í•™ìŠµì„ í•  ìˆ˜ ìˆë„ë¡ ê°œì¸í™” ëœ í•™ìŠµì„ ì œê³µí•˜ê³  ëª¨ë“  ì§ˆì˜ ì‘ë‹µì„ í•œêµ­ì–´ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\"\"\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-4o-mini-2024-07-18\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_msg},\n",
        "        {\"role\": \"user\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš”. íŒŒì´ì¬ ê¸°ì´ˆì— ëŒ€í•˜ì—¬ í•™ìŠµì„ ì§€ë„í•´ì¤˜ìš”\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"ë°˜ê°€ì™€ìš”~ íŒŒì´ì¬ ê¸°ì´ˆë¥¼ í•™ìŠµí•´ë³´ë„ë¡ í• ê²Œìš”. ë¨¼ì € íŒŒì´ì¬ì˜ ê¸°ë³¸ ë¬¸ë²•ê³¼ ê°œë…ë“¤ì„ ê°„ë‹¨íˆ ìš”ì•½í•´ë“œë¦´ê²Œìš”\"},\n",
        "        {\"role\": \"user\", \"content\": \"ë³€ìˆ˜ì™€ ìë£Œí˜•ì— ëŒ€í•´ í•™ìŠµí•´ì¤˜ìš”.\"},\n",
        "    ],\n",
        "    temperature=0.5,\n",
        "    max_tokens=300,\n",
        "    top_p=1,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT7hjCDywCS8",
        "outputId": "5a9ec8f9-9c26-4fcd-dbf7-05af347603c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì¢‹ì•„ìš”! ë³€ìˆ˜ëŠ” ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ê³µê°„ì´ê³ , ìë£Œí˜•ì€ ì €ì¥í•  ë°ì´í„°ì˜ ì¢…ë¥˜ë¥¼ ë‚˜íƒ€ë‚´ìš”. \n",
            "\n",
            "ì£¼ìš” ìë£Œí˜•:\n",
            "1. ì •ìˆ˜(int)\n",
            "2. ì‹¤ìˆ˜(float)\n",
            "3. ë¬¸ìì—´(str)\n",
            "4. ë¶ˆë¦¬ì–¸(bool)\n",
            "\n",
            "ì˜ˆì‹œ:\n",
            "```python\n",
            "x = 5        # ì •ìˆ˜\n",
            "y = 3.14     # ì‹¤ìˆ˜\n",
            "name = \"í™ê¸¸ë™\"  # ë¬¸ìì—´\n",
            "is_student = True  # ë¶ˆë¦¬ì–¸\n",
            "```\n",
            "\n",
            "ì´í•´ê°€ ì˜ ë˜ì—ˆë‚˜ìš”? ì—°ìŠµë¬¸ì œë¡œ ë³€ìˆ˜ë¥¼ 2ê°œ ë§Œë“¤ì–´ë³´ì„¸ìš”!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradio Web UI**\n",
        "- chat_with_tutor í•¨ìˆ˜: ì´ í•¨ìˆ˜ëŠ” OpenAI APIë¥¼ í˜¸ì¶œí•˜ì—¬ í•™ìƒì˜ ì…ë ¥ì— ëŒ€í•œ íŠœí„°ì˜ ì‘ë‹µì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì €ì¥í•˜ê³  ì´ì–´ì„œ ì§„í–‰í•©ë‹ˆë‹¤.\n",
        "- start_chat í•¨ìˆ˜: 'í•™ìŠµ ì‹œì‘' ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ íŠœí„°ì˜ ì¸ì‚¬ë§ê³¼ í•¨ê»˜ ëŒ€í™”ê°€ ì‹œì‘ë©ë‹ˆë‹¤.\n",
        "- Gradio UI:\n",
        "  - start_button: í•™ìŠµì„ ì‹œì‘í•˜ëŠ” ë²„íŠ¼ì…ë‹ˆë‹¤. ëˆ„ë¥´ë©´ íŠœí„°ì˜ ì¸ì‚¬ë§ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.\n",
        "  - tutor_response: íŠœí„°ì˜ ëŒ€ë‹µì„ í‘œì‹œí•˜ëŠ” í…ìŠ¤íŠ¸ë°•ìŠ¤ì…ë‹ˆë‹¤.\n",
        "  - user_input: í•™ìƒì´ ì§ˆë¬¸ì„ ì…ë ¥í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ë°•ìŠ¤ì…ë‹ˆë‹¤.\n",
        "  - submit_button: í•™ìƒì´ ì§ˆë¬¸ì„ ì œì¶œí•˜ëŠ” ë²„íŠ¼ì…ë‹ˆë‹¤.\n",
        "  - gr.State(): ëŒ€í™” ê¸°ë¡ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "te5sOkrBA8G9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "\n",
        "# OpenAI API\n",
        "openai.api_key = \"\"\n",
        "\n",
        "# ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì •\n",
        "system_message = \"\"\"ì½”ë”©íŠœí„°ëŠ” ê³ ë“±í•™ìƒ ì •ë³´ê³¼ëª©ì—ì„œ ì•Œê³ ë¦¬ì¦˜ê³¼ í”„ë¡œê·¸ë˜ë°ì„ í•™ìƒë“¤ì´ ì‹¤ìŠµí•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ëŠ” íŠœí„°ë´‡ì…ë‹ˆë‹¤.\n",
        "- íŠœí„°ëŠ” \"ë°˜ê°€ì™€ìš”~ \"ë¼ê³  ì¸ì‚¬ë§ë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
        "- í•™ìƒì´ ì„ íƒí•œ ì„¹ì…˜ìœ¼ë¡œ í•™ìŠµì„ ì‹œì‘í•˜ê³  ë¨¼ì € ê°„ë‹¨í•˜ê²Œ ì„¹ì…˜ í•™ìŠµë‚´ìš© ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "- ê° ì„¹ì…˜ë³„ í•™ìŠµ í•­ëª©ì— ëŒ€í•´ì„œ í•˜ë‚˜ì”© ê°œë…ì„ ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•˜ê³  ì—°ìŠµë¬¸ì œë¥¼ ì¶”ê°€ë¡œ ì œê³µí•´ì„œ ê° ê°œë…ì„ ì´í•´í•˜ì—¬ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì—°ìŠµí•©ë‹ˆë‹¤.\n",
        "- í•™ìƒì˜ ë‹µë³€ì— ëŒ€í•´ì„œ \"ì˜í–ˆì–´ìš”!\",\"ì¡°ê¸ˆ ë” ìƒê°í•´ë´ìš”~\" ì™€ ê°™ì€ ê¸ì •ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "- ëŒ€í™”ëŠ” ê°„ê²°í•˜ê²Œ ìœ ì§€í•˜ë©°, ìµœëŒ€ 100ì ì´ë‚´ë¡œ ì§„í–‰í•©ë‹ˆë‹¤. ë‹¨ ì½”ë“œëŠ” 300ì ì´ë‚´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.\n",
        "- íŠœí„°ëŠ” í•™ìƒë“¤ì´ ìê¸°ì£¼ë„ í•™ìŠµì„ í•  ìˆ˜ ìˆë„ë¡ ê°œì¸í™” ëœ í•™ìŠµì„ ì œê³µí•˜ê³  ëª¨ë“  ì§ˆì˜ ì‘ë‹µì„ í•œêµ­ì–´ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\"\"\"\n",
        "\n",
        "# ì±„íŒ…í•¨ìˆ˜\n",
        "def chat_with_tutor(user_input, chat_history):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_message}] + chat_history\n",
        "\n",
        "    if not chat_history:\n",
        "        messages.append({\"role\": \"user\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš”. íŒŒì´ì¬ ê¸°ì´ˆì— ëŒ€í•˜ì—¬ í•™ìŠµì„ ì§€ë„í•´ì¤˜ìš”\"})\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o-mini-2024-07-18\",\n",
        "        messages=messages,\n",
        "        temperature=0.5,\n",
        "        max_tokens=300,\n",
        "        top_p=1,\n",
        "    )\n",
        "\n",
        "    response_msg = response.choices[0].message.content\n",
        "    chat_history.append({\"role\": \"assistant\", \"content\": response_msg})\n",
        "\n",
        "    return response_msg, chat_history\n",
        "\n",
        "# Gradio UI êµ¬ì„±\n",
        "def start_chat():\n",
        "    return \"ì•ˆë…•í•˜ì„¸ìš”. íŒŒì´ì¬ ê¸°ì´ˆì— ëŒ€í•˜ì—¬ í•™ìŠµí•´ë³´ë„ë¡ í• ê²Œìš”. ë¨¼ì € íŒŒì´ì¬ì˜ ê¸°ë³¸ ë¬¸ë²•ê³¼ ê°œë…ë“¤ì„ ê°„ë‹¨íˆ ìš”ì•½í•´ë“œë¦´ê²Œìš”.\", []\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# íŒŒì´ì¬ íŠœí„° ë´‡\")\n",
        "\n",
        "    chat_history = gr.State([])\n",
        "\n",
        "    with gr.Row():\n",
        "        start_button = gr.Button(\"í•™ìŠµì‹œì‘\")\n",
        "\n",
        "    tutor_response = gr.Textbox(label=\"íŠœí„°ì˜ ëŒ€ë‹µ\")\n",
        "    user_input = gr.Textbox(label=\"í•™ìƒì˜ ì§ˆë¬¸\")\n",
        "\n",
        "    with gr.Row():\n",
        "        submit_button = gr.Button(\"ì§ˆë¬¸ ì œì¶œ\")\n",
        "\n",
        "    start_button.click(start_chat, inputs=[], outputs=[tutor_response, chat_history])\n",
        "    submit_button.click(chat_with_tutor, inputs=[user_input, chat_history], outputs=[tutor_response, chat_history])\n",
        "\n",
        "# ì‹¤í–‰\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "id": "Mf3f47glwCNE",
        "outputId": "018989a5-7d00-4cc2-a584-9e5bd1595717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://5f585d378e730349c2.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5f585d378e730349c2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://70150636b8e9eda61e.gradio.live\n",
            "Killing tunnel 127.0.0.1:7861 <> https://4cd620338b273f2e99.gradio.live\n",
            "Killing tunnel 127.0.0.1:7862 <> https://ee65c23610db5a2cb4.gradio.live\n",
            "Killing tunnel 127.0.0.1:7863 <> https://0b1943afc9057ef1b1.gradio.live\n",
            "Killing tunnel 127.0.0.1:7864 <> https://6b15399e7336c03bd5.gradio.live\n",
            "Killing tunnel 127.0.0.1:7865 <> https://366fc39d1520492956.gradio.live\n",
            "Killing tunnel 127.0.0.1:7866 <> https://3be58ea8128699c655.gradio.live\n",
            "Killing tunnel 127.0.0.1:7867 <> https://238da3bff695da86c4.gradio.live\n",
            "Killing tunnel 127.0.0.1:7868 <> https://d7d735f4f2079afe5d.gradio.live\n",
            "Killing tunnel 127.0.0.1:7869 <> https://64c15d1a68918cb0ab.gradio.live\n",
            "Killing tunnel 127.0.0.1:7870 <> https://5f585d378e730349c2.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install -q tiktoken\n",
        "# %pip install -q cohere\n",
        "%pip install -q openai\n",
        "%pip install -q gradio"
      ],
      "metadata": {
        "id": "-ZBO5JdrBoda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ê¸°ë³¸ ëª¨ë¸ - Fewshot"
      ],
      "metadata": {
        "id": "pZFXWL64H6oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"\")\n",
        "\n",
        "system_msg=\"\"\"ì½”ë”©íŠœí„°ëŠ” ê³ ë“±í•™ìƒ ì •ë³´ê³¼ëª©ì—ì„œ ì•Œê³ ë¦¬ì¦˜ê³¼ í”„ë¡œê·¸ë˜ë°ì„ í•™ìƒë“¤ì´ ì‹¤ìŠµí•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ëŠ” íŠœí„°ë´‡ì…ë‹ˆë‹¤.\n",
        "              - íŠœí„°ëŠ” \"ë°˜ê°€ì™€ìš”~ \"ë¼ê³  ì¸ì‚¬ë§ë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
        "              - í•™ìƒì´ ì„ íƒí•œ ì„¹ì…˜ìœ¼ë¡œ í•™ìŠµì„ ì‹œì‘í•˜ê³  ë¨¼ì € ê°„ë‹¨í•˜ê²Œ ì„¹ì…˜ í•™ìŠµë‚´ìš© ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "              - ê° ì„¹ì…˜ë³„ í•™ìŠµ í•­ëª©ì— ëŒ€í•´ì„œ í•˜ë‚˜ì”© ê°œë…ì„ ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•˜ê³  ì—°ìŠµë¬¸ì œë¥¼ ì¶”ê°€ë¡œ ì œê³µí•´ì„œ ê° ê°œë…ì„ ì´í•´í•˜ì—¬ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì—°ìŠµ ê¸°íšŒë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
        "              - í•™ìƒì˜ ë‹µë³€ì— ëŒ€í•´ì„œ \"ì˜í–ˆì–´ìš”!\",\"ì¡°ê¸ˆ ë” ìƒê°í•´ë´ìš”~\" ì™€ ê°™ì€ ê¸ì •ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "              - ëŒ€í™”ëŠ” ê°„ê²°í•˜ê²Œ ìœ ì§€í•˜ë©°, ìµœëŒ€ 100ì ì´ë‚´ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.ë‹¨ ì½”ë“œëŠ” 300ì ì´ë‚´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.\n",
        "              - íŠœí„°ëŠ” í•™ìƒë“¤ì´ ìê¸°ì£¼ë„ í•™ìŠµì„ í•  ìˆ˜ ìˆë„ë¡ ê°œì¸í™” ëœ í•™ìŠµì„ ì œê³µí•˜ê³  ëª¨ë“  ì§ˆì˜ ì‘ë‹µì„ í•œêµ­ì–´ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini-2024-07-18\",\n",
        "  messages = [\n",
        "        {\"role\": \"system\", \"content\": system_msg},\n",
        "        {\"role\": \"user\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš”. íŒŒì´ì¬ í•™ìŠµì„ ì‹œì‘í•´ì¤˜ìš”\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"ë°˜ê°€ì›Œìš”~ íŒŒì´ì¬ ê¸°ì´ˆë¥¼ í•™ìŠµí•´ë³´ë„ë¡ í• ê²Œìš”. ë¨¼ì € íŒŒì´ì¬ì˜ ê¸°ë³¸ ë¬¸ë²•ê³¼ ê°œë…ë“¤ì„ ê°„ë‹¨íˆ ìš”ì•½í•´ë“œë¦´ê²Œìš”.\"},\n",
        "        {\"role\": \"user\", \"content\": \"ë„¤\"},\n",
        "    ],\n",
        "\n",
        "  temperature=0.5,\n",
        "  max_tokens=300,\n",
        "  top_p=1,\n",
        ")\n",
        "\n",
        "response.choices[0].message.content"
      ],
      "metadata": {
        "id": "8kSoJbXLBobC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradio UI"
      ],
      "metadata": {
        "id": "GnztLfmyItUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "messages = [{\"role\": \"system\", \"content\": system_msg}] + chat_history\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_msg},<br>\n",
        "    {\"role\": \"user\", \"content\": \"íŒŒì´ì¬ì„ ë°°ìš°ê³  ì‹¶ì–´ìš”\"},<br>\n",
        "    {\"role\": \"assistant\", \"content\": \"ë°˜ê°€ì›Œìš”! íŒŒì´ì¬ ê¸°ì´ˆë¥¼ ì‹œì‘í•´ë³¼ê²Œìš”.\"}\n",
        "]"
      ],
      "metadata": {
        "id": "Qm78l3YDPfxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "í•™ìƒ ì…ë ¥ ë‚´ìš© ìœ í˜•ì— ì í•©í•œ íŠœí„° ì‘ë‹µ-function_call"
      ],
      "metadata": {
        "id": "VcB7O9u5d5Kj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**execute_code í•¨ìˆ˜**\n",
        "- exec()ë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì ìœ¼ë¡œ íŒŒì´ì¬ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ì„±ê³µ ë˜ëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€ë¡œ ë°˜í™˜í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” í•™ìƒì´ë‚˜ ì‚¬ìš©ìê°€ ì…ë ¥í•œ íŒŒì´ì¬ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” íŠœí„° ì‹œìŠ¤í…œ ë“±ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "- exec()ì˜ ë³´ì•ˆ ë¬¸ì œì— ì£¼ì˜í•˜ë©°, ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì´ë¥¼ ì•ˆì „í•˜ê²Œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì¶”ê°€ì ì¸ ë³´ì•ˆ ì¡°ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "**ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©ì„ ì œì¶œí•œ í›„ ì…ë ¥ í•„ë“œë¥¼ ë¹„ìš°ê¸°**\n",
        "submit_button.click() í˜¸ì¶œì—ì„œ, user_input í…ìŠ¤íŠ¸ë°•ìŠ¤ê°€ ì œì¶œëœ í›„ ë¹„ì›Œì§€ë„ë¡ í•˜ë ¤ë©´, outputsì— user_inputì„ í¬í•¨í•˜ê³  ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •í•˜ë©´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "```submit_button.click(chat_with_tutor, inputs=[user_input, chat_history], outputs=[tutor_response, chat_history, user_input], clear_on_submit=True)```"
      ],
      "metadata": {
        "id": "QLbNdvegeJ6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import io\n",
        "import sys\n",
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "# OpenAI API ì„¤ì •\n",
        "client = OpenAI(api_key=\"\")\n",
        "\n",
        "# ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì •\n",
        "system_msg=\"\"\"ì½”ë”©íŠœí„°ëŠ” ê³ ë“±í•™ìƒ ì •ë³´ê³¼ëª©ì—ì„œ ì•Œê³ ë¦¬ì¦˜ê³¼ í”„ë¡œê·¸ë˜ë°ì„ í•™ìƒë“¤ì´ ì‹¤ìŠµí•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ëŠ” íŠœí„°ë´‡ì…ë‹ˆë‹¤.\n",
        "              - íŠœí„°ëŠ” \"ë°˜ê°€ì™€ìš”~ \"ë¼ê³  ì¸ì‚¬ë§ë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
        "              - í•™ìƒì´ ì„ íƒí•œ ì„¹ì…˜ìœ¼ë¡œ í•™ìŠµì„ ì‹œì‘í•˜ê³  ë¨¼ì € ê°„ë‹¨í•˜ê²Œ ì„¹ì…˜ í•™ìŠµë‚´ìš© ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "              - ê° ì„¹ì…˜ë³„ í•™ìŠµ í•­ëª©ì— ëŒ€í•´ì„œ í•˜ë‚˜ì”© ê°œë…ì„ ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•˜ê³  ì—°ìŠµë¬¸ì œë¥¼ ì¶”ê°€ë¡œ ì œê³µí•´ì„œ ê° ê°œë…ì„ ì´í•´í•˜ì—¬ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì—°ìŠµ ê¸°íšŒë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
        "              - í•™ìƒì˜ ë‹µë³€ì— ëŒ€í•´ì„œ \"ì˜í–ˆì–´ìš”!\",\"ì¡°ê¸ˆ ë” ìƒê°í•´ë´ìš”~\" ì™€ ê°™ì€ ê¸ì •ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "              - ëŒ€í™”ëŠ” ê°„ê²°í•˜ê²Œ ìœ ì§€í•˜ë©°, ìµœëŒ€ 100ì ì´ë‚´ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.ë‹¨ ì½”ë“œëŠ” 300ì ì´ë‚´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.\n",
        "              - íŠœí„°ëŠ” í•™ìƒë“¤ì´ ìê¸°ì£¼ë„ í•™ìŠµì„ í•  ìˆ˜ ìˆë„ë¡ ê°œì¸í™” ëœ í•™ìŠµì„ ì œê³µí•˜ê³  ëª¨ë“  ì§ˆì˜ ì‘ë‹µì„ í•œêµ­ì–´ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\"\"\"\n",
        "\n",
        "# í•¨ìˆ˜ì •ì˜\n",
        "functions =[\n",
        "    {\n",
        "        \"name\": \"answer_question\",\n",
        "        \"description\": \"í•™ìƒì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"answer\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"ì§ˆë¬¸ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ë‹µë³€\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"answer\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"execute_code\",\n",
        "        \"description\": \"í•™ìƒì´ ì œì¶œí•œ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"code\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"í•™ìƒì´ ì‘ì„±í•œ íŒŒì´ì¬ ì½”ë“œ\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"code\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"handle_request\",\n",
        "        \"description\": \"í•™ìƒì˜ ìƒˆë¡œìš´ ìš”ì²­ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"request\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"í•™ìƒì˜ ìƒˆë¡œìš´ ìš”ì²­\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"request\"]\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# í•¨ìˆ˜ í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜\n",
        "def answer_question(answer):\n",
        "    return {\"answer\": answer}\n",
        "\n",
        "def execute_code(code):\n",
        "    # ì—¬ê¸°ì„œ ì½”ë“œë¥¼ ì‹¤ì œë¡œ ì‹¤í–‰í•˜ê±°ë‚˜ ì•ˆì „í•˜ê²Œ í‰ê°€í•˜ëŠ” ë¡œì§ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "    try:\n",
        "        exec_globals = {}\n",
        "        exec(code, exec_globals)\n",
        "        return {\"result\": \"ì½”ë“œ ì‹¤í–‰ ì„±ê³µ!\"}\n",
        "    except Exception as e:\n",
        "        return {\"result\": f\"ì½”ë“œ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}\"}\n",
        "\n",
        "def handle_request(request):\n",
        "    return {\"response\": f\"ìƒˆë¡œìš´ ìš”ì²­ '{request}'ì— ëŒ€í•œ ì²˜ë¦¬\"}\n",
        "\n",
        "# ì±„íŒ… í•¨ìˆ˜\n",
        "def chat_with_tutor(user_input, chat_history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_msg}] + chat_history\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    response = client.Chat.Completions.create(\n",
        "        model=\"gpt-4o-mini-2024-07-18\",\n",
        "        messages=messages,\n",
        "        functions=functions,\n",
        "        function_call = \"auto\",\n",
        "        temperature=0.5,\n",
        "        max_tokens=300,\n",
        "        top_p=1,\n",
        "    )\n",
        "\n",
        "# í•¨ìˆ˜ í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜\n",
        "def answer_question(answer):\n",
        "    return {\"answer\": answer}\n",
        "\n",
        "def execute_code(code):\n",
        "    # ì—¬ê¸°ì„œ ì½”ë“œë¥¼ ì‹¤ì œë¡œ ì‹¤í–‰í•˜ê±°ë‚˜ ì•ˆì „í•˜ê²Œ í‰ê°€í•˜ëŠ” ë¡œì§ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "    try:\n",
        "        # í‘œì¤€ ì¶œë ¥ì„ ì„ì‹œë¡œ StringIOë¡œ ë³€ê²½\n",
        "        output = io.StringIO()\n",
        "        sys.stdout = output\n",
        "\n",
        "        exec_globals = {}\n",
        "        exec(code, exec_globals)  # ì „ë‹¬ëœ ì½”ë“œë¥¼ ì‹¤í–‰\n",
        "\n",
        "        # í‘œì¤€ ì¶œë ¥ì„ ì›ë˜ëŒ€ë¡œ ë³µêµ¬\n",
        "        sys.stdout = sys.__stdout__\n",
        "\n",
        "        # ì¶œë ¥ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ê¸°\n",
        "        result = output.getvalue()\n",
        "\n",
        "        return {\"result\": result if result else \"ì½”ë“œ ì‹¤í–‰ ì„±ê³µ!\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        # í‘œì¤€ ì¶œë ¥ì„ ì›ë˜ëŒ€ë¡œ ë³µêµ¬ (ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„)\n",
        "        sys.stdout = sys.__stdout__\n",
        "        return {\"result\": f\"ì½”ë“œ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}\"}\n",
        "def handle_request(request):\n",
        "    return {\"response\": f\"ìƒˆë¡œìš´ ìš”ì²­ '{request}'ì— ëŒ€í•œ ì²˜ë¦¬\"}\n",
        "\n",
        "# ì±„íŒ… í•¨ìˆ˜\n",
        "def chat_with_tutor(user_input, chat_history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_msg}] + chat_history\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini-2024-07-18\",\n",
        "        messages=messages,\n",
        "        functions=functions,\n",
        "        function_call = \"auto\",\n",
        "        temperature=0.5,\n",
        "        max_tokens=300,\n",
        "        top_p=1,\n",
        "    )\n",
        "\n",
        "    # ëª¨ë¸ì˜ ì‘ë‹µì´ í•¨ìˆ˜ í˜¸ì¶œì„ ì œì•ˆí–ˆëŠ”ì§€ í™•ì¸\n",
        "    if response.choices[0].finish_reason == \"function_call\":\n",
        "        function_call = response.choices[0].message.function_call\n",
        "        function_name = function_call.name\n",
        "        function_args = json.loads(function_call.arguments)\n",
        "\n",
        "        if function_name == \"answer_question\":\n",
        "            result = answer_question(function_args[\"answer\"])\n",
        "            response_msg = f\"ì˜í–ˆì–´ìš”~ {result['answer']}ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤.\"\n",
        "        elif function_name == \"execute_code\":\n",
        "            result = execute_code(function_args[\"code\"])\n",
        "            response_msg = \"ì˜í–ˆì–´ìš”~ ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ê°€ ì„±ê³µì ì´ë„¤ìš”! ë” ì•Œê³  ì‹¶ì€ ê²ƒì´ ìˆë‚˜ìš”?\"\n",
        "        elif function_name == \"handle_request\":\n",
        "            result = handle_request(function_args[\"request\"])\n",
        "            response_msg = f\"'{result['response']}'ì„ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "    else:\n",
        "        response_msg = response.choices[0].message.content\n",
        "\n",
        "    chat_history.append({\"role\": \"assistant\", \"content\": response_msg})\n",
        "    return response_msg, chat_history, \"\"\n",
        "\n",
        "# Gradio UI êµ¬ì„±\n",
        "def start_chat():\n",
        "    return \"ë°˜ê°€ì›Œìš”~ íŒŒì´ì¬ ê¸°ì´ˆì— ëŒ€í•˜ì—¬ í•™ìŠµí•´ë³´ë„ë¡ í• ê²Œìš”. ë¨¼ì € íŒŒì´ì¬ì˜ ê¸°ë³¸ ë¬¸ë²•ê³¼ ê°œë…ë“¤ì„ ê°„ë‹¨íˆ ìš”ì•½í•´ë“œë¦´ê²Œìš”.\", []\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# íŒŒì´ì¬ íŠœí„° ë´‡\")\n",
        "\n",
        "    chat_history = gr.State([])\n",
        "\n",
        "    with gr.Row():\n",
        "        start_button = gr.Button(\"í•™ìŠµ ì‹œì‘\")\n",
        "\n",
        "    tutor_response = gr.Textbox(label=\"íŠœí„°ì˜ ëŒ€ë‹µ\")\n",
        "    user_input = gr.Textbox(label=\"í•™ìƒì˜ ì§ˆë¬¸\")\n",
        "\n",
        "    with gr.Row():\n",
        "        submit_button = gr.Button(\"ì§ˆë¬¸ ì œì¶œ\")\n",
        "\n",
        "    start_button.click(start_chat, inputs=[], outputs=[tutor_response, chat_history])\n",
        "    submit_button.click(chat_with_tutor, inputs=[user_input, chat_history], outputs=[tutor_response, chat_history])\n",
        "\n",
        "# ì‹¤í–‰\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "L3YLF96aBoUS",
        "outputId": "c879a3df-1664-4377-a68d-e095b83eca03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'OpenAI' from 'openai' (/usr/local/lib/python3.10/dist-packages/openai/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-605050fd0bf6>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# OpenAI API ì„¤ì •\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'openai' (/usr/local/lib/python3.10/dist-packages/openai/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "íƒ­ ë£¨ê°€ - íŠœí„°ë§ íˆìŠ¤í† ë¦¬, input í•¨ìˆ˜ ì…ë ¥ê°’ ì²˜ë¦¬"
      ],
      "metadata": {
        "id": "kZB-yQigerCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import io\n",
        "import sys\n",
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "# OpenAI API ì„¤ì •\n",
        "client = OpenAI(api_key=\"\")\n",
        "\n",
        "# ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì •\n",
        "system_msg=\"\"\"ì½”ë”©íŠœí„°ëŠ” ê³ ë“±í•™ìƒ ì •ë³´ê³¼ëª©ì—ì„œ ì•Œê³ ë¦¬ì¦˜ê³¼ í”„ë¡œê·¸ë˜ë°ì„ í•™ìƒë“¤ì´ ì‹¤ìŠµí•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ëŠ” íŠœí„°ë´‡ì…ë‹ˆë‹¤.\n",
        "              - íŠœí„°ëŠ” \"ë°˜ê°€ì™€ìš”~ \"ë¼ê³  ì¸ì‚¬ë§ë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
        "              - í•™ìƒì´ ì„ íƒí•œ ì„¹ì…˜ìœ¼ë¡œ í•™ìŠµì„ ì‹œì‘í•˜ê³  ë¨¼ì € ê°„ë‹¨í•˜ê²Œ ì„¹ì…˜ í•™ìŠµë‚´ìš© ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "              - ê° ì„¹ì…˜ë³„ í•™ìŠµ í•­ëª©ì— ëŒ€í•´ì„œ í•˜ë‚˜ì”© ê°œë…ì„ ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•˜ê³  ì—°ìŠµë¬¸ì œë¥¼ ì¶”ê°€ë¡œ ì œê³µí•´ì„œ ê° ê°œë…ì„ ì´í•´í•˜ì—¬ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì—°ìŠµ ê¸°íšŒë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
        "              - í•™ìƒì˜ ë‹µë³€ì— ëŒ€í•´ì„œ \"ì˜í–ˆì–´ìš”!\",\"ì¡°ê¸ˆ ë” ìƒê°í•´ë´ìš”~\" ì™€ ê°™ì€ ê¸ì •ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "              - ëŒ€í™”ëŠ” ê°„ê²°í•˜ê²Œ ìœ ì§€í•˜ë©°, ìµœëŒ€ 100ì ì´ë‚´ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.ë‹¨ ì½”ë“œëŠ” 300ì ì´ë‚´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.\n",
        "              - íŠœí„°ëŠ” í•™ìƒë“¤ì´ ìê¸°ì£¼ë„ í•™ìŠµì„ í•  ìˆ˜ ìˆë„ë¡ ê°œì¸í™” ëœ í•™ìŠµì„ ì œê³µí•˜ê³  ëª¨ë“  ì§ˆì˜ ì‘ë‹µì„ í•œêµ­ì–´ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\"\"\"\n",
        "\n",
        "# í•¨ìˆ˜ì •ì˜\n",
        "functions =[\n",
        "    {\n",
        "        \"name\": \"answer_question\",\n",
        "        \"description\": \"í•™ìƒì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"answer\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"ì§ˆë¬¸ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ë‹µë³€\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"answer\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"execute_code\",\n",
        "        \"description\": \"í•™ìƒì´ ì œì¶œí•œ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"code\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"í•™ìƒì´ ì‘ì„±í•œ íŒŒì´ì¬ ì½”ë“œ\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"code\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"handle_request\",\n",
        "        \"description\": \"í•™ìƒì˜ ìƒˆë¡œìš´ ìš”ì²­ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"request\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"í•™ìƒì˜ ìƒˆë¡œìš´ ìš”ì²­\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"request\"]\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# í•¨ìˆ˜ í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜\n",
        "def answer_question(answer):\n",
        "    return {\"answer\": answer}\n",
        "\n",
        "def execute_code(code):\n",
        "    # ì—¬ê¸°ì„œ ì½”ë“œë¥¼ ì‹¤ì œë¡œ ì‹¤í–‰í•˜ê±°ë‚˜ ì•ˆì „í•˜ê²Œ í‰ê°€í•˜ëŠ” ë¡œì§ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "    try:\n",
        "        exec_globals = {}\n",
        "        exec(code, exec_globals)\n",
        "        return {\"result\": \"ì½”ë“œ ì‹¤í–‰ ì„±ê³µ!\"}\n",
        "    except Exception as e:\n",
        "        return {\"result\": f\"ì½”ë“œ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}\"}\n",
        "\n",
        "def handle_request(request):\n",
        "    return {\"response\": f\"ìƒˆë¡œìš´ ìš”ì²­ '{request}'ì— ëŒ€í•œ ì²˜ë¦¬\"}\n",
        "\n",
        "# ì±„íŒ… í•¨ìˆ˜\n",
        "def chat_with_tutor(user_input, chat_history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_msg}] + chat_history\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    response = client.Chat.Completions.create(\n",
        "        model=\"gpt-4o-mini-2024-07-18\",\n",
        "        messages=messages,\n",
        "        functions=functions,\n",
        "        function_call = \"auto\",\n",
        "        temperature=0.5,\n",
        "        max_tokens=300,\n",
        "        top_p=1,\n",
        "    )\n",
        "\n",
        "# í•¨ìˆ˜ í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜\n",
        "def answer_question(answer):\n",
        "    return {\"answer\": answer}\n",
        "\n",
        "def execute_code(code):\n",
        "    # ì—¬ê¸°ì„œ ì½”ë“œë¥¼ ì‹¤ì œë¡œ ì‹¤í–‰í•˜ê±°ë‚˜ ì•ˆì „í•˜ê²Œ í‰ê°€í•˜ëŠ” ë¡œì§ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "    try:\n",
        "        # í‘œì¤€ ì¶œë ¥ì„ ì„ì‹œë¡œ StringIOë¡œ ë³€ê²½\n",
        "        output = io.StringIO()\n",
        "        sys.stdout = output\n",
        "\n",
        "        exec_globals = {}\n",
        "        exec(code, exec_globals)  # ì „ë‹¬ëœ ì½”ë“œë¥¼ ì‹¤í–‰\n",
        "\n",
        "        # í‘œì¤€ ì¶œë ¥ì„ ì›ë˜ëŒ€ë¡œ ë³µêµ¬\n",
        "        sys.stdout = sys.__stdout__\n",
        "\n",
        "        # ì¶œë ¥ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ê¸°\n",
        "        result = output.getvalue()\n",
        "\n",
        "        return {\"result\": result if result else \"ì½”ë“œ ì‹¤í–‰ ì„±ê³µ!\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        # í‘œì¤€ ì¶œë ¥ì„ ì›ë˜ëŒ€ë¡œ ë³µêµ¬ (ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„)\n",
        "        sys.stdout = sys.__stdout__\n",
        "        return {\"result\": f\"ì½”ë“œ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}\"}\n",
        "def handle_request(request):\n",
        "    return {\"response\": f\"ìƒˆë¡œìš´ ìš”ì²­ '{request}'ì— ëŒ€í•œ ì²˜ë¦¬\"}\n",
        "\n",
        "# ì±„íŒ… í•¨ìˆ˜\n",
        "def chat_with_tutor(user_input, chat_history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_msg}] + chat_history\n",
        "    chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini-2024-07-18\",\n",
        "        messages=messages,\n",
        "        functions=functions,\n",
        "        function_call = \"auto\",\n",
        "        temperature=0.5,\n",
        "        max_tokens=300,\n",
        "        top_p=1,\n",
        "    )\n",
        "\n",
        "    # ëª¨ë¸ì˜ ì‘ë‹µì´ í•¨ìˆ˜ í˜¸ì¶œì„ ì œì•ˆí–ˆëŠ”ì§€ í™•ì¸\n",
        "    if response.choices[0].finish_reason == \"function_call\":\n",
        "        function_call = response.choices[0].message.function_call\n",
        "        function_name = function_call.name\n",
        "        function_args = json.loads(function_call.arguments)\n",
        "\n",
        "        if function_name == \"answer_question\":\n",
        "            result = answer_question(function_args[\"answer\"])\n",
        "            response_msg = f\"ì˜í–ˆì–´ìš”~ {result['answer']}ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤.\"\n",
        "        elif function_name == \"execute_code\":\n",
        "            result = execute_code(function_args[\"code\"])\n",
        "            response_msg = \"ì˜í–ˆì–´ìš”~ ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ê°€ ì„±ê³µì ì´ë„¤ìš”! ë” ì•Œê³  ì‹¶ì€ ê²ƒì´ ìˆë‚˜ìš”?\"\n",
        "        elif function_name == \"handle_request\":\n",
        "            result = handle_request(function_args[\"request\"])\n",
        "            response_msg = f\"'{result['response']}'ì„ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "    else:\n",
        "        response_msg = response.choices[0].message.content\n",
        "\n",
        "    chat_history.append({\"role\": \"assistant\", \"content\": response_msg})\n",
        "    return response_msg, chat_history, \"\"\n",
        "\n",
        "# Gradio UI êµ¬ì„±\n",
        "def start_chat():\n",
        "    return \"ë°˜ê°€ì›Œìš”~ íŒŒì´ì¬ ê¸°ì´ˆì— ëŒ€í•˜ì—¬ í•™ìŠµí•´ë³´ë„ë¡ í• ê²Œìš”. ë¨¼ì € íŒŒì´ì¬ì˜ ê¸°ë³¸ ë¬¸ë²•ê³¼ ê°œë…ë“¤ì„ ê°„ë‹¨íˆ ìš”ì•½í•´ë“œë¦´ê²Œìš”.\", []\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# íŒŒì´ì¬ íŠœí„° ë´‡\")\n",
        "\n",
        "    chat_history = gr.State([])\n",
        "\n",
        "    with gr.Tabs():  # íƒ­ ì¶”ê°€\n",
        "        with gr.TabItem(\"í•™ìŠµ ëŒ€í™”\"):\n",
        "            tutor_response = gr.Textbox(label=\"íŠœí„°\")\n",
        "            user_input = gr.Textbox(label=\"í•™ìƒ\")\n",
        "\n",
        "            with gr.Row():\n",
        "                start_button = gr.Button(\"í•™ìŠµ\")\n",
        "                submit_button = gr.Button(\"ì œì¶œ\")\n",
        "\n",
        "            start_button.click(start_chat, inputs=[], outputs=[tutor_response, chat_history])\n",
        "            submit_button.click(chat_with_tutor, inputs=[user_input, chat_history], outputs=[tutor_response, chat_history, user_input])\n",
        "\n",
        "        with gr.TabItem(\"íŠœí„°ë§ íˆìŠ¤í† ë¦¬\"):  # íˆìŠ¤í† ë¦¬ íƒ­ ì¶”ê°€\n",
        "            history_display = gr.Markdown(value=\"\")  # íˆìŠ¤í† ë¦¬ í‘œì‹œìš© Markdown\n",
        "\n",
        "            def update_history(chat_history):\n",
        "                # íˆìŠ¤í† ë¦¬ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…\n",
        "                formatted_history = \"\"\n",
        "                for entry in chat_history:\n",
        "                    role = \"íŠœí„°\" if entry['role'] == \"assistant\" else \"í•™ìƒ\"\n",
        "                    formatted_history += f\"**{role}**: {entry['content']}\\n\\n\"\n",
        "                return formatted_history\n",
        "\n",
        "            # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸\n",
        "            submit_button.click(update_history, inputs=[chat_history], outputs=[history_display])\n",
        "\n",
        "# ì‹¤í–‰\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "i5stXkrZBoPz",
        "outputId": "0b88babd-b7b2-4df8-a759-e3d688e5dd55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'OpenAI' from 'openai' (/usr/local/lib/python3.10/dist-packages/openai/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-8a3d922035d5>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# OpenAI API ì„¤ì •\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'openai' (/usr/local/lib/python3.10/dist-packages/openai/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web UIì—ì„œ input í•¨ìˆ˜ ì²˜ë¦¬"
      ],
      "metadata": {
        "id": "bamGSG98kPZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import gradio as gr\n",
        "\n",
        "# ì½”ë“œ ì‹¤í–‰ í•¨ìˆ˜ ì •ì˜\n",
        "def execute_code(code, user_input_value):\n",
        "    try:\n",
        "        # ì‚¬ìš©ìë¡œë¶€í„° ì…ë ¥ì„ ë°›ëŠ” input() í•¨ìˆ˜ ëŒ€ì²´ (ì •ê·œ í‘œí˜„ì‹ ì‚¬ìš©)\n",
        "        if user_input_value:  # user_input_valueê°€ ìˆì„ ë•Œë§Œ ëŒ€ì²´\n",
        "            # ì •ê·œ í‘œí˜„ì‹ìœ¼ë¡œ input() í•¨ìˆ˜ ì „ì²´ë¥¼ ëŒ€ì²´ (ê´„í˜¸ í¬í•¨)\n",
        "            code = re.sub(r'input\\((.*?)\\)', f'\"{user_input_value}\"', code)\n",
        "\n",
        "        # ë””ë²„ê¹…ì„ ìœ„í•œ ì¶œë ¥: ëŒ€ì²´ëœ ì½”ë“œ í™•ì¸\n",
        "        print(f\"ëŒ€ì²´ëœ ì½”ë“œ:\\n{code}\")\n",
        "\n",
        "        # ì½”ë“œ ì‹¤í–‰ í™˜ê²½ ì„¤ì •\n",
        "        exec_globals = {}\n",
        "        exec_output = []\n",
        "\n",
        "        # print ì¶œë ¥ì„ ìˆ˜ì§‘í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ ì¬ì •ì˜\n",
        "        def custom_print(*args):\n",
        "            exec_output.append(\" \".join(map(str, args)))\n",
        "\n",
        "        # print í•¨ìˆ˜ë¥¼ custom_printë¡œ ëŒ€ì²´ (ì¶œë ¥ê°’ ìˆ˜ì§‘)\n",
        "        exec_globals['print'] = custom_print\n",
        "\n",
        "        # ì½”ë“œ ì‹¤í–‰\n",
        "        exec(code, exec_globals)\n",
        "\n",
        "        # ì‹¤í–‰ ê²°ê³¼ ë°˜í™˜ (ìˆ˜ì§‘ëœ ì¶œë ¥)\n",
        "        exec_output_str = \"\\n\".join(exec_output) if exec_output else \"ì½”ë“œ ì‹¤í–‰ ì„±ê³µ!\"\n",
        "        return exec_output_str\n",
        "    except Exception as e:\n",
        "        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë°˜í™˜\n",
        "        return f\"ì½”ë“œ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}\"\n",
        "\n",
        "# input() í•¨ìˆ˜ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜\n",
        "def check_for_input_function(code):\n",
        "    # ì •ê·œ í‘œí˜„ì‹ìœ¼ë¡œ input() í•¨ìˆ˜ê°€ í¬í•¨ëœ ì½”ë“œ ê°ì§€\n",
        "    return bool(re.search(r'input\\((.*?)\\)', code))\n",
        "\n",
        "# Gradio ì¸í„°í˜ì´ìŠ¤ ì •ì˜\n",
        "with gr.Blocks() as demo:\n",
        "    # ì½”ë“œ ì…ë ¥ ë° input() ê°’ì„ ë°›ì„ í…ìŠ¤íŠ¸ ë°•ìŠ¤\n",
        "    code_input = gr.Textbox(label=\"ì½”ë“œ ì…ë ¥\", placeholder=\"input()ì„ í¬í•¨í•œ ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”\", lines=10)\n",
        "\n",
        "    # input() ê°’ ì…ë ¥ ì°½, ê¸°ë³¸ì ìœ¼ë¡œ ìˆ¨ê¹€\n",
        "    user_input_value = gr.Textbox(label=\"input() ê°’ ì…ë ¥\", placeholder=\"input() ê°’\", visible=False)\n",
        "\n",
        "    # ê²°ê³¼ ì¶œë ¥ìš© í…ìŠ¤íŠ¸ ë°•ìŠ¤\n",
        "    code_output = gr.Textbox(label=\"ì½”ë“œ ì‹¤í–‰ ê²°ê³¼\", placeholder=\"ì—¬ê¸°ì— ì‹¤í–‰ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤\")\n",
        "\n",
        "    # ì½”ë“œ ì‹¤í–‰ ë²„íŠ¼\n",
        "    code_run_button = gr.Button(\"ì½”ë“œ ì‹¤í–‰\")\n",
        "\n",
        "    # ì½”ë“œì—ì„œ input() í•¨ìˆ˜ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì—¬ ì…ë ¥ì°½ í‘œì‹œ\n",
        "    def handle_code_execution(code):\n",
        "        # input() í•¨ìˆ˜ê°€ ìˆëŠ”ì§€ í™•ì¸ (ì •ê·œ í‘œí˜„ì‹ ì‚¬ìš©)\n",
        "        if check_for_input_function(code):\n",
        "            return gr.update(visible=True), \"\"  # input ì°½ì„ ë³´ì´ê²Œ í•˜ê³ , ì‹¤í–‰ ê²°ê³¼ëŠ” ì•„ì§ ì—†ìŒ\n",
        "        else:\n",
        "            output = execute_code(code, None)  # input() ê°’ ì—†ì´ ì½”ë“œ ì‹¤í–‰\n",
        "            return gr.update(visible=False), output  # input ì°½ì„ ìˆ¨ê¸°ê³ , ì½”ë“œ ë°”ë¡œ ì‹¤í–‰\n",
        "\n",
        "    # ìµœì¢… ì½”ë“œ ì‹¤í–‰ (input() í•¨ìˆ˜ ê°’ ì…ë ¥ í›„)\n",
        "    def execute_with_input(code, user_input_value):\n",
        "        output = execute_code(code, user_input_value)\n",
        "        return output\n",
        "\n",
        "    # ë²„íŠ¼ í´ë¦­ ì‹œ ì½”ë“œì—ì„œ input()ì„ ê°ì§€í•´ ì°½ì„ í‘œì‹œí•˜ê±°ë‚˜ ë°”ë¡œ ì‹¤í–‰\n",
        "    code_run_button.click(handle_code_execution, inputs=[code_input], outputs=[user_input_value, code_output])\n",
        "\n",
        "    # input() ê°’ ì…ë ¥ í›„ ì½”ë“œ ì‹¤í–‰\n",
        "    user_input_value.submit(execute_with_input, inputs=[code_input, user_input_value], outputs=[code_output])\n",
        "\n",
        "# Gradio ì›¹ UI ì‹¤í–‰\n",
        "demo.launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "tds_6sMEtBw0",
        "outputId": "be3ead9c-1e72-465e-fe69-212fd6c432f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://67a3d13ecbe0f83dbe.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://67a3d13ecbe0f83dbe.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ëŒ€ì²´ëœ ì½”ë“œ:\n",
            "int(\"5\")\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://67a3d13ecbe0f83dbe.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## íƒ­ì¶”ê°€ - ì½”ë“œ ì‹¤í–‰"
      ],
      "metadata": {
        "id": "IvUL9C3gkYw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ê³¼ì œ\n",
        "Task1_0826. input í•¨ìˆ˜ê°€ ì²˜ë¦¬ë˜ë„ë¡ ì½”ë“œë¥¼ ìˆ˜ì •í•´ì„œ ì‹¤í–‰í•´ ë³´ì„¸ìš”."
      ],
      "metadata": {
        "id": "RTyVO4Woubqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import gradio as gr\n",
        "\n",
        "# ì½”ë“œ ì‹¤í–‰ í•¨ìˆ˜ ì •ì˜\n",
        "def execute_code(code, user_input_value):\n",
        "    try:\n",
        "        # ì‚¬ìš©ìë¡œë¶€í„° ì…ë ¥ì„ ë°›ëŠ” input() í•¨ìˆ˜ ëŒ€ì²´ (ì •ê·œ í‘œí˜„ì‹ ì‚¬ìš©)\n",
        "        if user_input_value:  # user_input_valueê°€ ìˆì„ ë•Œë§Œ ëŒ€ì²´\n",
        "            # ì •ê·œ í‘œí˜„ì‹ìœ¼ë¡œ input() í•¨ìˆ˜ ì „ì²´ë¥¼ ëŒ€ì²´ (ê´„í˜¸ í¬í•¨)\n",
        "            code = re.sub(r'input\\((.*?)\\)', f'\"{user_input_value}\"', code)\n",
        "\n",
        "        # ë””ë²„ê¹…ì„ ìœ„í•œ ì¶œë ¥: ëŒ€ì²´ëœ ì½”ë“œ í™•ì¸\n",
        "        print(f\"ëŒ€ì²´ëœ ì½”ë“œ:\\n{code}\")\n",
        "\n",
        "        # ì½”ë“œ ì‹¤í–‰ í™˜ê²½ ì„¤ì •\n",
        "        exec_globals = {}\n",
        "        exec_output = []\n",
        "\n",
        "        # print ì¶œë ¥ì„ ìˆ˜ì§‘í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ ì¬ì •ì˜\n",
        "        def custom_print(*args):\n",
        "            exec_output.append(\" \".join(map(str, args)))\n",
        "\n",
        "        # print í•¨ìˆ˜ë¥¼ custom_printë¡œ ëŒ€ì²´ (ì¶œë ¥ê°’ ìˆ˜ì§‘)\n",
        "        exec_globals['print'] = custom_print\n",
        "\n",
        "        # ì½”ë“œ ì‹¤í–‰\n",
        "        exec(code, exec_globals)\n",
        "\n",
        "        # ì‹¤í–‰ ê²°ê³¼ ë°˜í™˜ (ìˆ˜ì§‘ëœ ì¶œë ¥)\n",
        "        exec_output_str = \"\\n\".join(exec_output) if exec_output else \"ì½”ë“œ ì‹¤í–‰ ì„±ê³µ!\"\n",
        "        return exec_output_str\n",
        "    except Exception as e:\n",
        "        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë°˜í™˜\n",
        "        return f\"ì½”ë“œ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}\"\n",
        "\n",
        "# input() í•¨ìˆ˜ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜\n",
        "def check_for_input_function(code):\n",
        "    # ì •ê·œ í‘œí˜„ì‹ìœ¼ë¡œ input() í•¨ìˆ˜ê°€ í¬í•¨ëœ ì½”ë“œ ê°ì§€\n",
        "    return bool(re.search(r'input\\((.*?)\\)', code))\n",
        "\n",
        "# Gradio ì¸í„°í˜ì´ìŠ¤ ì •ì˜\n",
        "with gr.Blocks() as demo:\n",
        "    # ì½”ë“œ ì…ë ¥ ë° input() ê°’ì„ ë°›ì„ í…ìŠ¤íŠ¸ ë°•ìŠ¤\n",
        "    code_input = gr.Textbox(label=\"ì½”ë“œ ì…ë ¥\", placeholder=\"input()ì„ í¬í•¨í•œ ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”\", lines=10)\n",
        "\n",
        "    # input() ê°’ ì…ë ¥ ì°½, ê¸°ë³¸ì ìœ¼ë¡œ ìˆ¨ê¹€\n",
        "    user_input_value = gr.Textbox(label=\"input() ê°’ ì…ë ¥\", placeholder=\"input() ê°’\", visible=False)\n",
        "\n",
        "    # ê²°ê³¼ ì¶œë ¥ìš© í…ìŠ¤íŠ¸ ë°•ìŠ¤\n",
        "    code_output = gr.Textbox(label=\"ì½”ë“œ ì‹¤í–‰ ê²°ê³¼\", placeholder=\"ì—¬ê¸°ì— ì‹¤í–‰ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤\")\n",
        "\n",
        "    # ì½”ë“œ ì‹¤í–‰ ë²„íŠ¼\n",
        "    code_run_button = gr.Button(\"ì½”ë“œ ì‹¤í–‰\")\n",
        "\n",
        "    # ì½”ë“œì—ì„œ input() í•¨ìˆ˜ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì—¬ ì…ë ¥ì°½ í‘œì‹œ\n",
        "    def handle_code_execution(code):\n",
        "        # input() í•¨ìˆ˜ê°€ ìˆëŠ”ì§€ í™•ì¸ (ì •ê·œ í‘œí˜„ì‹ ì‚¬ìš©)\n",
        "        if check_for_input_function(code):\n",
        "            return gr.update(visible=True), \"\"  # input ì°½ì„ ë³´ì´ê²Œ í•˜ê³ , ì‹¤í–‰ ê²°ê³¼ëŠ” ì•„ì§ ì—†ìŒ\n",
        "        else:\n",
        "            output = execute_code(code, None)  # input() ê°’ ì—†ì´ ì½”ë“œ ì‹¤í–‰\n",
        "            return gr.update(visible=False), output  # input ì°½ì„ ìˆ¨ê¸°ê³ , ì½”ë“œ ë°”ë¡œ ì‹¤í–‰\n",
        "\n",
        "    # ìµœì¢… ì½”ë“œ ì‹¤í–‰ (input() í•¨ìˆ˜ ê°’ ì…ë ¥ í›„)\n",
        "    def execute_with_input(code, user_input_value):\n",
        "        output = execute_code(code, user_input_value)\n",
        "        return output\n",
        "\n",
        "    # ë²„íŠ¼ í´ë¦­ ì‹œ ì½”ë“œì—ì„œ input()ì„ ê°ì§€í•´ ì°½ì„ í‘œì‹œí•˜ê±°ë‚˜ ë°”ë¡œ ì‹¤í–‰\n",
        "    code_run_button.click(handle_code_execution, inputs=[code_input], outputs=[user_input_value, code_output])\n",
        "\n",
        "    # input() ê°’ ì…ë ¥ í›„ ì½”ë“œ ì‹¤í–‰\n",
        "    user_input_value.submit(execute_with_input, inputs=[code_input, user_input_value], outputs=[code_output])\n",
        "\n",
        "# Gradio ì›¹ UI ì‹¤í–‰\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "EE2cT1pWBoJi",
        "outputId": "bc9fdbd6-e34e-41a2-fb0a-c656d02cf510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://2cdb20e8c50ccfabbc.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2cdb20e8c50ccfabbc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ëŒ€ì²´ëœ ì½”ë“œ:\n",
            "int(\"5\")\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://2cdb20e8c50ccfabbc.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}